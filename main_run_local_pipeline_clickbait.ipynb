{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MAIN RUN LOCAL_PIPELINE**\n",
    "\n",
    "(NB: Penjelasan tahap-tahap ada di bawah section ini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "p2A6Y6anAHL4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tfx\n",
      "Version: 1.14.0\n",
      "Summary: TensorFlow Extended (TFX) is a TensorFlow-based general-purpose machine learning platform implemented at Google.\n",
      "Home-page: https://www.tensorflow.org/tfx\n",
      "Author: Google LLC\n",
      "Author-email: tensorflow-extended-dev@googlegroups.com\n",
      "License: Apache 2.0\n",
      "Location: /mnt/B28A5BE18A5BA0A1/DataKu/Downloads/ALTER_CODING/MLOPS_CLOUDEKA/ubuntu/env2/lib/python3.9/site-packages\n",
      "Requires: absl-py, apache-beam, attrs, click, docker, google-api-core, google-api-python-client, google-apitools, google-cloud-aiplatform, google-cloud-bigquery, grpcio, jinja2, keras-tuner, kubernetes, ml-metadata, ml-pipelines-sdk, numpy, packaging, portpicker, protobuf, pyarrow, pyyaml, tensorflow, tensorflow-data-validation, tensorflow-hub, tensorflow-model-analysis, tensorflow-serving-api, tensorflow-transform, tfx-bsl, typing-extensions\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show tfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "BKa9adbFAYr0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34;42m.\u001b[0m\n",
      "├── \u001b[34;42mconfig\u001b[0m\n",
      "│   └── \u001b[01;32mprometheus.config\u001b[0m\n",
      "├── \u001b[34;42mdataset\u001b[0m\n",
      "│   └── \u001b[01;32mclickbait.csv\u001b[0m\n",
      "├── \u001b[01;32mDockerfile\u001b[0m\n",
      "├── \u001b[01;32mmain_runlocal_pipeline_clickbait.ipynb\u001b[0m\n",
      "├── \u001b[01;32mlocal_pipeline.py\u001b[0m\n",
      "├── \u001b[34;42mmodules\u001b[0m\n",
      "│   ├── \u001b[01;32mcomponents.py\u001b[0m\n",
      "│   ├── \u001b[01;32mtrainer.py\u001b[0m\n",
      "│   ├── \u001b[01;32mtransform.py\u001b[0m\n",
      "│   └── \u001b[01;32mtuner.py\u001b[0m\n",
      "├── \u001b[34;42mmonitoring\u001b[0m\n",
      "│   ├── \u001b[01;32mDockerfile\u001b[0m\n",
      "│   └── \u001b[01;32mprometheus.yml\u001b[0m\n",
      "├── \u001b[01;32mPylint_check.ipynb\u001b[0m\n",
      "└── \u001b[01;32mrequirements.txt\u001b[0m\n",
      "\n",
      "4 directories, 13 files\n"
     ]
    }
   ],
   "source": [
    "!tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bd_lNhG8A6qn",
    "outputId": "3ec9b430-480d-40d6-baea-11ddbc4ff799"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "INFO:absl:Node Evaluator depends on ['Run[CsvExampleGen]', 'Run[Latest_blessed_model_resolver]', 'Run[Trainer]'].\n",
      "INFO:absl:Node Evaluator is scheduled.\n",
      "INFO:absl:Node Pusher depends on ['Run[Evaluator]', 'Run[Trainer]'].\n",
      "INFO:absl:Node Pusher is scheduled.\n",
      "INFO:absl:node Latest_blessed_model_resolver is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.dsl.components.common.resolver.Resolver\"\n",
      "  }\n",
      "  id: \"Latest_blessed_model_resolver\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"sitomb-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"20240329-084051.264027\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"sitomb-pipeline.Latest_blessed_model_resolver\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"_generated_model_3\"\n",
      "    value {\n",
      "      channels {\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      hidden: true\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"_generated_modelblessing_4\"\n",
      "    value {\n",
      "      channels {\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"ModelBlessing\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      hidden: true\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      input_graph_ref {\n",
      "        graph_id: \"graph_1\"\n",
      "        key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"model_blessing\"\n",
      "    value {\n",
      "      input_graph_ref {\n",
      "        graph_id: \"graph_1\"\n",
      "        key: \"model_blessing\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  input_graphs {\n",
      "    key: \"graph_1\"\n",
      "    value {\n",
      "      nodes {\n",
      "        key: \"dict_2\"\n",
      "        value {\n",
      "          output_data_type: ARTIFACT_MULTIMAP\n",
      "          dict_node {\n",
      "            node_ids {\n",
      "              key: \"model\"\n",
      "              value: \"input_3\"\n",
      "            }\n",
      "            node_ids {\n",
      "              key: \"model_blessing\"\n",
      "              value: \"input_4\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        key: \"input_3\"\n",
      "        value {\n",
      "          output_data_type: ARTIFACT_LIST\n",
      "          input_node {\n",
      "            input_key: \"_generated_model_3\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        key: \"input_4\"\n",
      "        value {\n",
      "          output_data_type: ARTIFACT_LIST\n",
      "          input_node {\n",
      "            input_key: \"_generated_modelblessing_4\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        key: \"op_1\"\n",
      "        value {\n",
      "          output_data_type: ARTIFACT_MULTIMAP\n",
      "          op_node {\n",
      "            op_type: \"tfx.dsl.input_resolution.strategies.latest_blessed_model_strategy.LatestBlessedModelStrategy\"\n",
      "            args {\n",
      "              node_id: \"dict_2\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      result_node: \"op_1\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"Evaluator\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "    enable_cache: true\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:Running as an resolver node.\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:[Latest_blessed_model_resolver] Resolved inputs: ({'model': [], 'model_blessing': []},)\n",
      "INFO:absl:node Latest_blessed_model_resolver is finished.\n",
      "INFO:absl:node CsvExampleGen is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.example_gen.csv_example_gen.component.CsvExampleGen\"\n",
      "  }\n",
      "  id: \"CsvExampleGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"sitomb-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"20240329-084051.264027\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"sitomb-pipeline.CsvExampleGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Examples\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          properties {\n",
      "            key: \"version\"\n",
      "            value: INT\n",
      "          }\n",
      "          base_type: DATASET\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"input_base\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"dataset\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"input_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"*\\\"\\n    }\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 8,\\n        \\\"name\\\": \\\"train\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 2,\\n        \\\"name\\\": \\\"eval\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_data_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 6\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_file_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 5\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"Evaluator\"\n",
      "downstream_nodes: \"StatisticsGen\"\n",
      "downstream_nodes: \"Transform\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "    enable_cache: true\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:[CsvExampleGen] Resolved inputs: ({},)\n",
      "INFO:absl:select span and version = (0, None)\n",
      "INFO:absl:latest span and version = (0, None)\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:A cached execution 29 is used.\n",
      "INFO:absl:node CsvExampleGen is finished.\n",
      "INFO:absl:node StatisticsGen is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n",
      "    base_type: PROCESS\n",
      "  }\n",
      "  id: \"StatisticsGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"sitomb-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"20240329-084051.264027\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"sitomb-pipeline.StatisticsGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"CsvExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20240329-084051.264027\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline.CsvExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"statistics\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleStatistics\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          base_type: STATISTICS\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"exclude_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"[]\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"CsvExampleGen\"\n",
      "downstream_nodes: \"ExampleValidator\"\n",
      "downstream_nodes: \"SchemaGen\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "    enable_cache: true\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "INFO:absl:[StatisticsGen] Resolved inputs: ({'examples': [Artifact(artifact: id: 1\n",
      "type_id: 16\n",
      "uri: \"output/sitomb-pipeline/CsvExampleGen/examples/2\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"file_format\"\n",
      "  value {\n",
      "    string_value: \"tfrecords_gzip\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"input_fingerprint\"\n",
      "  value {\n",
      "    string_value: \"split:single_split,num_files:1,total_bytes:1835039,xor_checksum:1711592832,sum_checksum:1711592832\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"payload_format\"\n",
      "  value {\n",
      "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.14.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Examples\"\n",
      "create_time_since_epoch: 1711698900986\n",
      "last_update_time_since_epoch: 1711698900986\n",
      ", artifact_type: id: 16\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]},)\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:A cached execution 30 is used.\n",
      "INFO:absl:node StatisticsGen is finished.\n",
      "INFO:absl:node SchemaGen is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.schema_gen.component.SchemaGen\"\n",
      "    base_type: PROCESS\n",
      "  }\n",
      "  id: \"SchemaGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"sitomb-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"20240329-084051.264027\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"sitomb-pipeline.SchemaGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"statistics\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"StatisticsGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20240329-084051.264027\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline.StatisticsGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"ExampleStatistics\"\n",
      "            base_type: STATISTICS\n",
      "          }\n",
      "        }\n",
      "        output_key: \"statistics\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Schema\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"exclude_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"[]\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"infer_feature_shape\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"StatisticsGen\"\n",
      "downstream_nodes: \"ExampleValidator\"\n",
      "downstream_nodes: \"Trainer\"\n",
      "downstream_nodes: \"Transform\"\n",
      "downstream_nodes: \"Tuner\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "    enable_cache: true\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "INFO:absl:[SchemaGen] Resolved inputs: ({'statistics': [Artifact(artifact: id: 2\n",
      "type_id: 18\n",
      "uri: \"output/sitomb-pipeline/StatisticsGen/statistics/3\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"stats_dashboard_link\"\n",
      "  value {\n",
      "    string_value: \"\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.14.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"ExampleStatistics\"\n",
      "create_time_since_epoch: 1711698906329\n",
      "last_update_time_since_epoch: 1711698906329\n",
      ", artifact_type: id: 18\n",
      "name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "base_type: STATISTICS\n",
      ")]},)\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:A cached execution 31 is used.\n",
      "INFO:absl:node SchemaGen is finished.\n",
      "INFO:absl:node ExampleValidator is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.example_validator.component.ExampleValidator\"\n",
      "  }\n",
      "  id: \"ExampleValidator\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"sitomb-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"20240329-084051.264027\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"sitomb-pipeline.ExampleValidator\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"SchemaGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20240329-084051.264027\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline.SchemaGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"schema\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"statistics\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"StatisticsGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20240329-084051.264027\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline.StatisticsGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"ExampleStatistics\"\n",
      "            base_type: STATISTICS\n",
      "          }\n",
      "        }\n",
      "        output_key: \"statistics\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"anomalies\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleAnomalies\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"exclude_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"[]\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"SchemaGen\"\n",
      "upstream_nodes: \"StatisticsGen\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "    enable_cache: true\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "INFO:absl:[ExampleValidator] Resolved inputs: ({'statistics': [Artifact(artifact: id: 2\n",
      "type_id: 18\n",
      "uri: \"output/sitomb-pipeline/StatisticsGen/statistics/3\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"stats_dashboard_link\"\n",
      "  value {\n",
      "    string_value: \"\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.14.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"ExampleStatistics\"\n",
      "create_time_since_epoch: 1711698906329\n",
      "last_update_time_since_epoch: 1711698906329\n",
      ", artifact_type: id: 18\n",
      "name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "base_type: STATISTICS\n",
      ")], 'schema': [Artifact(artifact: id: 3\n",
      "type_id: 20\n",
      "uri: \"output/sitomb-pipeline/SchemaGen/schema/4\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.14.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Schema\"\n",
      "create_time_since_epoch: 1711698906564\n",
      "last_update_time_since_epoch: 1711698906564\n",
      ", artifact_type: id: 20\n",
      "name: \"Schema\"\n",
      ")]},)\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:A cached execution 32 is used.\n",
      "INFO:absl:node ExampleValidator is finished.\n",
      "INFO:absl:node Transform is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.transform.component.Transform\"\n",
      "    base_type: TRANSFORM\n",
      "  }\n",
      "  id: \"Transform\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"sitomb-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"20240329-084051.264027\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"sitomb-pipeline.Transform\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"CsvExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20240329-084051.264027\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline.CsvExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"SchemaGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20240329-084051.264027\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline.SchemaGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"schema\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"post_transform_anomalies\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleAnomalies\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"post_transform_schema\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Schema\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"post_transform_stats\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleStatistics\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          base_type: STATISTICS\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"pre_transform_schema\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Schema\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"pre_transform_stats\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleStatistics\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          base_type: STATISTICS\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"transform_graph\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"TransformGraph\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"transformed_examples\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Examples\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          properties {\n",
      "            key: \"version\"\n",
      "            value: INT\n",
      "          }\n",
      "          base_type: DATASET\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"updated_analyzer_cache\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"TransformCache\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"disable_statistics\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"force_tf_compat_v1\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"module_path\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"transform@output/sitomb-pipeline/_wheels/tfx_user_code_Transform-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f-py3-none-any.whl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"CsvExampleGen\"\n",
      "upstream_nodes: \"SchemaGen\"\n",
      "downstream_nodes: \"Trainer\"\n",
      "downstream_nodes: \"Tuner\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "    enable_cache: true\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "INFO:absl:[Transform] Resolved inputs: ({'schema': [Artifact(artifact: id: 3\n",
      "type_id: 20\n",
      "uri: \"output/sitomb-pipeline/SchemaGen/schema/4\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.14.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Schema\"\n",
      "create_time_since_epoch: 1711698906564\n",
      "last_update_time_since_epoch: 1711698906564\n",
      ", artifact_type: id: 20\n",
      "name: \"Schema\"\n",
      ")], 'examples': [Artifact(artifact: id: 1\n",
      "type_id: 16\n",
      "uri: \"output/sitomb-pipeline/CsvExampleGen/examples/2\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"file_format\"\n",
      "  value {\n",
      "    string_value: \"tfrecords_gzip\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"input_fingerprint\"\n",
      "  value {\n",
      "    string_value: \"split:single_split,num_files:1,total_bytes:1835039,xor_checksum:1711592832,sum_checksum:1711592832\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"payload_format\"\n",
      "  value {\n",
      "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.14.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Examples\"\n",
      "create_time_since_epoch: 1711698900986\n",
      "last_update_time_since_epoch: 1711698900986\n",
      ", artifact_type: id: 16\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]},)\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 33\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=33, input_dict={'schema': [Artifact(artifact: id: 3\n",
      "type_id: 20\n",
      "uri: \"output/sitomb-pipeline/SchemaGen/schema/4\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.14.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Schema\"\n",
      "create_time_since_epoch: 1711698906564\n",
      "last_update_time_since_epoch: 1711698906564\n",
      ", artifact_type: id: 20\n",
      "name: \"Schema\"\n",
      ")], 'examples': [Artifact(artifact: id: 1\n",
      "type_id: 16\n",
      "uri: \"output/sitomb-pipeline/CsvExampleGen/examples/2\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"file_format\"\n",
      "  value {\n",
      "    string_value: \"tfrecords_gzip\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"input_fingerprint\"\n",
      "  value {\n",
      "    string_value: \"split:single_split,num_files:1,total_bytes:1835039,xor_checksum:1711592832,sum_checksum:1711592832\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"payload_format\"\n",
      "  value {\n",
      "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.14.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Examples\"\n",
      "create_time_since_epoch: 1711698900986\n",
      "last_update_time_since_epoch: 1711698900986\n",
      ", artifact_type: id: 16\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'transform_graph': [Artifact(artifact: uri: \"output/sitomb-pipeline/Transform/transform_graph/33\"\n",
      ", artifact_type: name: \"TransformGraph\"\n",
      ")], 'updated_analyzer_cache': [Artifact(artifact: uri: \"output/sitomb-pipeline/Transform/updated_analyzer_cache/33\"\n",
      ", artifact_type: name: \"TransformCache\"\n",
      ")], 'post_transform_schema': [Artifact(artifact: uri: \"output/sitomb-pipeline/Transform/post_transform_schema/33\"\n",
      ", artifact_type: name: \"Schema\"\n",
      ")], 'post_transform_anomalies': [Artifact(artifact: uri: \"output/sitomb-pipeline/Transform/post_transform_anomalies/33\"\n",
      ", artifact_type: name: \"ExampleAnomalies\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      ")], 'pre_transform_schema': [Artifact(artifact: uri: \"output/sitomb-pipeline/Transform/pre_transform_schema/33\"\n",
      ", artifact_type: name: \"Schema\"\n",
      ")], 'pre_transform_stats': [Artifact(artifact: uri: \"output/sitomb-pipeline/Transform/pre_transform_stats/33\"\n",
      ", artifact_type: name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "base_type: STATISTICS\n",
      ")], 'post_transform_stats': [Artifact(artifact: uri: \"output/sitomb-pipeline/Transform/post_transform_stats/33\"\n",
      ", artifact_type: name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "base_type: STATISTICS\n",
      ")], 'transformed_examples': [Artifact(artifact: uri: \"output/sitomb-pipeline/Transform/transformed_examples/33\"\n",
      ", artifact_type: name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}), exec_properties={'force_tf_compat_v1': 0, 'module_path': 'transform@output/sitomb-pipeline/_wheels/tfx_user_code_Transform-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f-py3-none-any.whl', 'custom_config': 'null', 'disable_statistics': 0}, execution_output_uri='output/sitomb-pipeline/Transform/.system/executor_execution/33/executor_output.pb', stateful_working_dir='output/sitomb-pipeline/Transform/.system/stateful_working_dir/20240329-084051.264027', tmp_dir='output/sitomb-pipeline/Transform/.system/executor_execution/33/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.transform.component.Transform\"\n",
      "    base_type: TRANSFORM\n",
      "  }\n",
      "  id: \"Transform\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"sitomb-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"20240329-084051.264027\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"sitomb-pipeline.Transform\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"CsvExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20240329-084051.264027\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline.CsvExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"SchemaGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20240329-084051.264027\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline.SchemaGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"schema\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"post_transform_anomalies\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleAnomalies\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"post_transform_schema\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Schema\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"post_transform_stats\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleStatistics\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          base_type: STATISTICS\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"pre_transform_schema\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Schema\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"pre_transform_stats\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleStatistics\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          base_type: STATISTICS\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"transform_graph\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"TransformGraph\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"transformed_examples\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Examples\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          properties {\n",
      "            key: \"version\"\n",
      "            value: INT\n",
      "          }\n",
      "          base_type: DATASET\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"updated_analyzer_cache\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"TransformCache\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"disable_statistics\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"force_tf_compat_v1\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"module_path\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"transform@output/sitomb-pipeline/_wheels/tfx_user_code_Transform-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f-py3-none-any.whl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"CsvExampleGen\"\n",
      "upstream_nodes: \"SchemaGen\"\n",
      "downstream_nodes: \"Trainer\"\n",
      "downstream_nodes: \"Tuner\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "    enable_cache: true\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"sitomb-pipeline\"\n",
      ", pipeline_run_id='20240329-084051.264027', top_level_pipeline_run_id=None)\n",
      "INFO:absl:Analyze the 'train' split and transform all splits when splits_config is not set.\n",
      "INFO:absl:udf_utils.get_fn {'module_file': None, 'module_path': 'transform@output/sitomb-pipeline/_wheels/tfx_user_code_Transform-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f-py3-none-any.whl', 'preprocessing_fn': None} 'preprocessing_fn'\n",
      "INFO:absl:Installing 'output/sitomb-pipeline/_wheels/tfx_user_code_Transform-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f-py3-none-any.whl' to a temporary directory.\n",
      "INFO:absl:Executing: ['/usr/bin/python3', '-m', 'pip', 'install', '--target', '/tmp/tmpit018vg7', 'output/sitomb-pipeline/_wheels/tfx_user_code_Transform-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f-py3-none-any.whl']\n",
      "Processing ./output/sitomb-pipeline/_wheels/tfx_user_code_Transform-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f-py3-none-any.whl\n",
      "Installing collected packages: tfx-user-code-Transform\n",
      "Successfully installed tfx-user-code-Transform-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f\n",
      "INFO:absl:Successfully installed 'output/sitomb-pipeline/_wheels/tfx_user_code_Transform-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f-py3-none-any.whl'.\n",
      "INFO:absl:udf_utils.get_fn {'module_file': None, 'module_path': 'transform@output/sitomb-pipeline/_wheels/tfx_user_code_Transform-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f-py3-none-any.whl', 'stats_options_updater_fn': None} 'stats_options_updater_fn'\n",
      "INFO:absl:Installing 'output/sitomb-pipeline/_wheels/tfx_user_code_Transform-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f-py3-none-any.whl' to a temporary directory.\n",
      "INFO:absl:Executing: ['/usr/bin/python3', '-m', 'pip', 'install', '--target', '/tmp/tmp9bkw_5nu', 'output/sitomb-pipeline/_wheels/tfx_user_code_Transform-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f-py3-none-any.whl']\n",
      "Processing ./output/sitomb-pipeline/_wheels/tfx_user_code_Transform-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f-py3-none-any.whl\n",
      "Installing collected packages: tfx-user-code-Transform\n",
      "Successfully installed tfx-user-code-Transform-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f\n",
      "INFO:absl:Successfully installed 'output/sitomb-pipeline/_wheels/tfx_user_code_Transform-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f-py3-none-any.whl'.\n",
      "INFO:absl:Installing 'output/sitomb-pipeline/_wheels/tfx_user_code_Transform-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f-py3-none-any.whl' to a temporary directory.\n",
      "INFO:absl:Executing: ['/usr/bin/python3', '-m', 'pip', 'install', '--target', '/tmp/tmpp4p38ey3', 'output/sitomb-pipeline/_wheels/tfx_user_code_Transform-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f-py3-none-any.whl']\n",
      "Processing ./output/sitomb-pipeline/_wheels/tfx_user_code_Transform-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f-py3-none-any.whl\n",
      "Installing collected packages: tfx-user-code-Transform\n",
      "Successfully installed tfx-user-code-Transform-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f\n",
      "INFO:absl:Successfully installed 'output/sitomb-pipeline/_wheels/tfx_user_code_Transform-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f-py3-none-any.whl'.\n",
      "INFO:absl:Feature clickbait has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature headline has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature clickbait has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature headline has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature clickbait has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature headline has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature clickbait has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature headline has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature clickbait has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature headline has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature clickbait has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature headline has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature clickbait has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature headline has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature clickbait has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature headline has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature clickbait has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature headline has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature clickbait has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature headline has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature clickbait has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature headline has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Writing fingerprint to output/sitomb-pipeline/Transform/transform_graph/33/.temp_path/tftransform_tmp/f86a809bdd814577868c993a3f5c1489/fingerprint.pb\n",
      "INFO:absl:Feature clickbait_xf has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature headline_xf has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature clickbait_xf has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature headline_xf has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "WARNING:apache_beam.io.tfrecordio:Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 33 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'transform_graph': [Artifact(artifact: uri: \"output/sitomb-pipeline/Transform/transform_graph/33\"\n",
      ", artifact_type: name: \"TransformGraph\"\n",
      ")], 'updated_analyzer_cache': [Artifact(artifact: uri: \"output/sitomb-pipeline/Transform/updated_analyzer_cache/33\"\n",
      ", artifact_type: name: \"TransformCache\"\n",
      ")], 'post_transform_schema': [Artifact(artifact: uri: \"output/sitomb-pipeline/Transform/post_transform_schema/33\"\n",
      ", artifact_type: name: \"Schema\"\n",
      ")], 'post_transform_anomalies': [Artifact(artifact: uri: \"output/sitomb-pipeline/Transform/post_transform_anomalies/33\"\n",
      ", artifact_type: name: \"ExampleAnomalies\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      ")], 'pre_transform_schema': [Artifact(artifact: uri: \"output/sitomb-pipeline/Transform/pre_transform_schema/33\"\n",
      ", artifact_type: name: \"Schema\"\n",
      ")], 'pre_transform_stats': [Artifact(artifact: uri: \"output/sitomb-pipeline/Transform/pre_transform_stats/33\"\n",
      ", artifact_type: name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "base_type: STATISTICS\n",
      ")], 'post_transform_stats': [Artifact(artifact: uri: \"output/sitomb-pipeline/Transform/post_transform_stats/33\"\n",
      ", artifact_type: name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "base_type: STATISTICS\n",
      ")], 'transformed_examples': [Artifact(artifact: uri: \"output/sitomb-pipeline/Transform/transformed_examples/33\"\n",
      ", artifact_type: name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}) for execution 33\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:node Transform is finished.\n",
      "INFO:absl:node Tuner is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.tuner.component.Tuner\"\n",
      "  }\n",
      "  id: \"Tuner\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"sitomb-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"20240329-084051.264027\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"sitomb-pipeline.Tuner\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Transform\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20240329-084051.264027\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline.Transform\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"transformed_examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"SchemaGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20240329-084051.264027\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline.SchemaGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"schema\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"transform_graph\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Transform\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20240329-084051.264027\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline.Transform\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"TransformGraph\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"transform_graph\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"best_hyperparameters\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"HyperParameters\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"tuner_results\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"TunerResults\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"eval_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 1000,\\n  \\\"splits\\\": [\\n    \\\"eval\\\"\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"module_path\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"tuner@output/sitomb-pipeline/_wheels/tfx_user_code_Tuner-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f-py3-none-any.whl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"train_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 5000,\\n  \\\"splits\\\": [\\n    \\\"train\\\"\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"SchemaGen\"\n",
      "upstream_nodes: \"Transform\"\n",
      "downstream_nodes: \"Trainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "    enable_cache: true\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "INFO:absl:[Tuner] Resolved inputs: ({'transform_graph': [Artifact(artifact: id: 23\n",
      "type_id: 24\n",
      "uri: \"output/sitomb-pipeline/Transform/transform_graph/33\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.14.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"TransformGraph\"\n",
      "create_time_since_epoch: 1711701690904\n",
      "last_update_time_since_epoch: 1711701690904\n",
      ", artifact_type: id: 24\n",
      "name: \"TransformGraph\"\n",
      ")], 'schema': [Artifact(artifact: id: 3\n",
      "type_id: 20\n",
      "uri: \"output/sitomb-pipeline/SchemaGen/schema/4\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.14.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Schema\"\n",
      "create_time_since_epoch: 1711698906564\n",
      "last_update_time_since_epoch: 1711698906564\n",
      ", artifact_type: id: 20\n",
      "name: \"Schema\"\n",
      ")], 'examples': [Artifact(artifact: id: 30\n",
      "type_id: 16\n",
      "uri: \"output/sitomb-pipeline/Transform/transformed_examples/33\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.14.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Examples\"\n",
      "create_time_since_epoch: 1711701690906\n",
      "last_update_time_since_epoch: 1711701690906\n",
      ", artifact_type: id: 16\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]},)\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 34\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=34, input_dict={'transform_graph': [Artifact(artifact: id: 23\n",
      "type_id: 24\n",
      "uri: \"output/sitomb-pipeline/Transform/transform_graph/33\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.14.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"TransformGraph\"\n",
      "create_time_since_epoch: 1711701690904\n",
      "last_update_time_since_epoch: 1711701690904\n",
      ", artifact_type: id: 24\n",
      "name: \"TransformGraph\"\n",
      ")], 'schema': [Artifact(artifact: id: 3\n",
      "type_id: 20\n",
      "uri: \"output/sitomb-pipeline/SchemaGen/schema/4\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.14.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Schema\"\n",
      "create_time_since_epoch: 1711698906564\n",
      "last_update_time_since_epoch: 1711698906564\n",
      ", artifact_type: id: 20\n",
      "name: \"Schema\"\n",
      ")], 'examples': [Artifact(artifact: id: 30\n",
      "type_id: 16\n",
      "uri: \"output/sitomb-pipeline/Transform/transformed_examples/33\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.14.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Examples\"\n",
      "create_time_since_epoch: 1711701690906\n",
      "last_update_time_since_epoch: 1711701690906\n",
      ", artifact_type: id: 16\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'tuner_results': [Artifact(artifact: uri: \"output/sitomb-pipeline/Tuner/tuner_results/34\"\n",
      ", artifact_type: name: \"TunerResults\"\n",
      ")], 'best_hyperparameters': [Artifact(artifact: uri: \"output/sitomb-pipeline/Tuner/best_hyperparameters/34\"\n",
      ", artifact_type: name: \"HyperParameters\"\n",
      ")]}), exec_properties={'train_args': '{\\n  \"num_steps\": 5000,\\n  \"splits\": [\\n    \"train\"\\n  ]\\n}', 'custom_config': 'null', 'eval_args': '{\\n  \"num_steps\": 1000,\\n  \"splits\": [\\n    \"eval\"\\n  ]\\n}', 'module_path': 'tuner@output/sitomb-pipeline/_wheels/tfx_user_code_Tuner-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f-py3-none-any.whl'}, execution_output_uri='output/sitomb-pipeline/Tuner/.system/executor_execution/34/executor_output.pb', stateful_working_dir='output/sitomb-pipeline/Tuner/.system/stateful_working_dir/20240329-084051.264027', tmp_dir='output/sitomb-pipeline/Tuner/.system/executor_execution/34/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.tuner.component.Tuner\"\n",
      "  }\n",
      "  id: \"Tuner\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"sitomb-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"20240329-084051.264027\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"sitomb-pipeline.Tuner\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Transform\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20240329-084051.264027\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline.Transform\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"transformed_examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"SchemaGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20240329-084051.264027\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline.SchemaGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"schema\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"transform_graph\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Transform\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20240329-084051.264027\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline.Transform\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"TransformGraph\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"transform_graph\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"best_hyperparameters\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"HyperParameters\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"tuner_results\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"TunerResults\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"eval_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 1000,\\n  \\\"splits\\\": [\\n    \\\"eval\\\"\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"module_path\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"tuner@output/sitomb-pipeline/_wheels/tfx_user_code_Tuner-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f-py3-none-any.whl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"train_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 5000,\\n  \\\"splits\\\": [\\n    \\\"train\\\"\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"SchemaGen\"\n",
      "upstream_nodes: \"Transform\"\n",
      "downstream_nodes: \"Trainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "    enable_cache: true\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"sitomb-pipeline\"\n",
      ", pipeline_run_id='20240329-084051.264027', top_level_pipeline_run_id=None)\n",
      "INFO:absl:Creating temp directory at output/sitomb-pipeline/Tuner/.system/executor_execution/34/.temp/34/\n",
      "INFO:absl:udf_utils.get_fn {'train_args': '{\\n  \"num_steps\": 5000,\\n  \"splits\": [\\n    \"train\"\\n  ]\\n}', 'custom_config': 'null', 'eval_args': '{\\n  \"num_steps\": 1000,\\n  \"splits\": [\\n    \"eval\"\\n  ]\\n}', 'module_path': 'tuner@output/sitomb-pipeline/_wheels/tfx_user_code_Tuner-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f-py3-none-any.whl'} 'tuner_fn'\n",
      "INFO:absl:Installing 'output/sitomb-pipeline/_wheels/tfx_user_code_Tuner-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f-py3-none-any.whl' to a temporary directory.\n",
      "INFO:absl:Executing: ['/usr/bin/python3', '-m', 'pip', 'install', '--target', '/tmp/tmp41y_sh3w', 'output/sitomb-pipeline/_wheels/tfx_user_code_Tuner-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f-py3-none-any.whl']\n",
      "Processing ./output/sitomb-pipeline/_wheels/tfx_user_code_Tuner-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f-py3-none-any.whl\n",
      "Installing collected packages: tfx-user-code-Tuner\n",
      "Successfully installed tfx-user-code-Tuner-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f\n",
      "INFO:absl:Successfully installed 'output/sitomb-pipeline/_wheels/tfx_user_code_Tuner-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f-py3-none-any.whl'.\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "INFO:absl:Feature clickbait_xf has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature headline_xf has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/data/experimental/ops/readers.py:1086: parse_example_dataset (from tensorflow.python.data.experimental.ops.parsing_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map(tf.io.parse_example(...))` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/data/experimental/ops/readers.py:1086: parse_example_dataset (from tensorflow.python.data.experimental.ops.parsing_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map(tf.io.parse_example(...))` instead.\n",
      "INFO:absl:Feature clickbait_xf has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature headline_xf has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "DEBUG: Start_vectorizer_adapt\n",
      "DEBUG: Finish Vectorizer Adapt\n",
      "Search space summary\n",
      "Default search space size: 6\n",
      "num_hidden_layers (Choice)\n",
      "{'default': 1, 'conditions': [], 'values': [1, 2, 3], 'ordered': True}\n",
      "embed_dims (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 256, 'step': 32, 'sampling': 'linear'}\n",
      "lstm_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 256, 'step': 32, 'sampling': 'linear'}\n",
      "dense_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 64, 'max_value': 512, 'step': 64, 'sampling': 'linear'}\n",
      "dropout_rate (Float)\n",
      "{'default': 0.2, 'conditions': [], 'min_value': 0.2, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001, 1e-05], 'ordered': True}\n",
      "INFO:absl:Start tuning... Tuner ID: tuner0\n",
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Trial ke-1\n",
      "Panjang_Trials: 0\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "2                 |2                 |num_hidden_layers\n",
      "176               |176               |embed_dims\n",
      "160               |160               |lstm_units\n",
      "128               |128               |dense_units\n",
      "0.2               |0.2               |dropout_rate\n",
      "1e-05             |1e-05             |learning_rate\n",
      "1                 |1                 |tuner/epochs\n",
      "0                 |0                 |tuner/initial_epoch\n",
      "0                 |0                 |tuner/bracket\n",
      "0                 |0                 |tuner/round\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5805: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n",
      "50/50 [==============================] - 43s 778ms/step - loss: 0.6811 - binary_accuracy: 0.9328 - val_loss: 0.6940 - val_binary_accuracy: 0.5025\n",
      "Trial 1 Complete [00h 00m 45s]\n",
      "val_binary_accuracy: 0.5024999976158142\n",
      "\n",
      "Trial ke-1\n",
      "Panjang_Trials: 1\n",
      "Best val_binary_accuracy So Far: 0.5024999976158142\n",
      "Total elapsed time: 00h 00m 45s\n",
      "INFO:absl:Finished tuning... Tuner ID: tuner0\n",
      "Results summary\n",
      "Results in output/sitomb-pipeline/Tuner/.system/executor_execution/34/.temp/34/clickbait_detection_hyperband_kt\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_binary_accuracy\", direction=\"max\")\n",
      "Trial ke-10\n",
      "Panjang_Trials: 1\n",
      "\n",
      "Trial 0000 summary\n",
      "Hyperparameters:\n",
      "num_hidden_layers: 2\n",
      "embed_dims: 176\n",
      "lstm_units: 160\n",
      "dense_units: 128\n",
      "dropout_rate: 0.2\n",
      "learning_rate: 1e-05\n",
      "tuner/epochs: 1\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.5024999976158142\n",
      "Trial ke-1\n",
      "Panjang_Trials: 1\n",
      "INFO:absl:Best HyperParameters: {'space': [{'class_name': 'Choice', 'config': {'name': 'num_hidden_layers', 'default': 1, 'conditions': [], 'values': [1, 2, 3], 'ordered': True}}, {'class_name': 'Int', 'config': {'name': 'embed_dims', 'default': None, 'conditions': [], 'min_value': 16, 'max_value': 256, 'step': 32, 'sampling': 'linear'}}, {'class_name': 'Int', 'config': {'name': 'lstm_units', 'default': None, 'conditions': [], 'min_value': 32, 'max_value': 256, 'step': 32, 'sampling': 'linear'}}, {'class_name': 'Int', 'config': {'name': 'dense_units', 'default': None, 'conditions': [], 'min_value': 64, 'max_value': 512, 'step': 64, 'sampling': 'linear'}}, {'class_name': 'Float', 'config': {'name': 'dropout_rate', 'default': 0.2, 'conditions': [], 'min_value': 0.2, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}}, {'class_name': 'Choice', 'config': {'name': 'learning_rate', 'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001, 1e-05], 'ordered': True}}], 'values': {'num_hidden_layers': 2, 'embed_dims': 176, 'lstm_units': 160, 'dense_units': 128, 'dropout_rate': 0.2, 'learning_rate': 1e-05, 'tuner/epochs': 1, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}}\n",
      "INFO:absl:Best Hyperparameters are written to output/sitomb-pipeline/Tuner/best_hyperparameters/34/best_hyperparameters.txt.\n",
      "Trial ke-None\n",
      "Panjang_Trials: 1\n",
      "INFO:absl:Tuner results are written to output/sitomb-pipeline/Tuner/tuner_results/34/tuner_results.json.\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 34 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'tuner_results': [Artifact(artifact: uri: \"output/sitomb-pipeline/Tuner/tuner_results/34\"\n",
      ", artifact_type: name: \"TunerResults\"\n",
      ")], 'best_hyperparameters': [Artifact(artifact: uri: \"output/sitomb-pipeline/Tuner/best_hyperparameters/34\"\n",
      ", artifact_type: name: \"HyperParameters\"\n",
      ")]}) for execution 34\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:node Tuner is finished.\n",
      "INFO:absl:node Trainer is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.trainer.component.Trainer\"\n",
      "    base_type: TRAIN\n",
      "  }\n",
      "  id: \"Trainer\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"sitomb-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"20240329-084051.264027\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"sitomb-pipeline.Trainer\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Transform\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20240329-084051.264027\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline.Transform\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"transformed_examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"hyperparameters\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Tuner\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20240329-084051.264027\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline.Tuner\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"HyperParameters\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"best_hyperparameters\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"SchemaGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20240329-084051.264027\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline.SchemaGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"schema\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"transform_graph\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Transform\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20240329-084051.264027\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline.Transform\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"TransformGraph\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"transform_graph\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Model\"\n",
      "          base_type: MODEL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"model_run\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelRun\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"eval_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 1000,\\n  \\\"splits\\\": [\\n    \\\"eval\\\"\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"module_path\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"trainer@output/sitomb-pipeline/_wheels/tfx_user_code_Trainer-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f-py3-none-any.whl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"train_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 5000,\\n  \\\"splits\\\": [\\n    \\\"train\\\"\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"SchemaGen\"\n",
      "upstream_nodes: \"Transform\"\n",
      "upstream_nodes: \"Tuner\"\n",
      "downstream_nodes: \"Evaluator\"\n",
      "downstream_nodes: \"Pusher\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "    enable_cache: true\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "INFO:absl:[Trainer] Resolved inputs: ({'hyperparameters': [Artifact(artifact: id: 32\n",
      "type_id: 27\n",
      "uri: \"output/sitomb-pipeline/Tuner/best_hyperparameters/34\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.14.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"HyperParameters\"\n",
      "create_time_since_epoch: 1711701744787\n",
      "last_update_time_since_epoch: 1711701744787\n",
      ", artifact_type: id: 27\n",
      "name: \"HyperParameters\"\n",
      ")], 'schema': [Artifact(artifact: id: 3\n",
      "type_id: 20\n",
      "uri: \"output/sitomb-pipeline/SchemaGen/schema/4\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.14.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Schema\"\n",
      "create_time_since_epoch: 1711698906564\n",
      "last_update_time_since_epoch: 1711698906564\n",
      ", artifact_type: id: 20\n",
      "name: \"Schema\"\n",
      ")], 'transform_graph': [Artifact(artifact: id: 23\n",
      "type_id: 24\n",
      "uri: \"output/sitomb-pipeline/Transform/transform_graph/33\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.14.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"TransformGraph\"\n",
      "create_time_since_epoch: 1711701690904\n",
      "last_update_time_since_epoch: 1711701690904\n",
      ", artifact_type: id: 24\n",
      "name: \"TransformGraph\"\n",
      ")], 'examples': [Artifact(artifact: id: 30\n",
      "type_id: 16\n",
      "uri: \"output/sitomb-pipeline/Transform/transformed_examples/33\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.14.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Examples\"\n",
      "create_time_since_epoch: 1711701690906\n",
      "last_update_time_since_epoch: 1711701690906\n",
      ", artifact_type: id: 16\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]},)\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 35\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=35, input_dict={'hyperparameters': [Artifact(artifact: id: 32\n",
      "type_id: 27\n",
      "uri: \"output/sitomb-pipeline/Tuner/best_hyperparameters/34\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.14.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"HyperParameters\"\n",
      "create_time_since_epoch: 1711701744787\n",
      "last_update_time_since_epoch: 1711701744787\n",
      ", artifact_type: id: 27\n",
      "name: \"HyperParameters\"\n",
      ")], 'schema': [Artifact(artifact: id: 3\n",
      "type_id: 20\n",
      "uri: \"output/sitomb-pipeline/SchemaGen/schema/4\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.14.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Schema\"\n",
      "create_time_since_epoch: 1711698906564\n",
      "last_update_time_since_epoch: 1711698906564\n",
      ", artifact_type: id: 20\n",
      "name: \"Schema\"\n",
      ")], 'transform_graph': [Artifact(artifact: id: 23\n",
      "type_id: 24\n",
      "uri: \"output/sitomb-pipeline/Transform/transform_graph/33\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.14.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"TransformGraph\"\n",
      "create_time_since_epoch: 1711701690904\n",
      "last_update_time_since_epoch: 1711701690904\n",
      ", artifact_type: id: 24\n",
      "name: \"TransformGraph\"\n",
      ")], 'examples': [Artifact(artifact: id: 30\n",
      "type_id: 16\n",
      "uri: \"output/sitomb-pipeline/Transform/transformed_examples/33\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.14.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Examples\"\n",
      "create_time_since_epoch: 1711701690906\n",
      "last_update_time_since_epoch: 1711701690906\n",
      ", artifact_type: id: 16\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'model_run': [Artifact(artifact: uri: \"output/sitomb-pipeline/Trainer/model_run/35\"\n",
      ", artifact_type: name: \"ModelRun\"\n",
      ")], 'model': [Artifact(artifact: uri: \"output/sitomb-pipeline/Trainer/model/35\"\n",
      ", artifact_type: name: \"Model\"\n",
      "base_type: MODEL\n",
      ")]}), exec_properties={'custom_config': 'null', 'module_path': 'trainer@output/sitomb-pipeline/_wheels/tfx_user_code_Trainer-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f-py3-none-any.whl', 'eval_args': '{\\n  \"num_steps\": 1000,\\n  \"splits\": [\\n    \"eval\"\\n  ]\\n}', 'train_args': '{\\n  \"num_steps\": 5000,\\n  \"splits\": [\\n    \"train\"\\n  ]\\n}'}, execution_output_uri='output/sitomb-pipeline/Trainer/.system/executor_execution/35/executor_output.pb', stateful_working_dir='output/sitomb-pipeline/Trainer/.system/stateful_working_dir/20240329-084051.264027', tmp_dir='output/sitomb-pipeline/Trainer/.system/executor_execution/35/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.trainer.component.Trainer\"\n",
      "    base_type: TRAIN\n",
      "  }\n",
      "  id: \"Trainer\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"sitomb-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"20240329-084051.264027\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"sitomb-pipeline.Trainer\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Transform\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20240329-084051.264027\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline.Transform\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"transformed_examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"hyperparameters\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Tuner\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20240329-084051.264027\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline.Tuner\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"HyperParameters\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"best_hyperparameters\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"SchemaGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20240329-084051.264027\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline.SchemaGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"schema\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"transform_graph\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Transform\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20240329-084051.264027\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline.Transform\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"TransformGraph\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"transform_graph\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Model\"\n",
      "          base_type: MODEL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"model_run\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelRun\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"eval_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 1000,\\n  \\\"splits\\\": [\\n    \\\"eval\\\"\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"module_path\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"trainer@output/sitomb-pipeline/_wheels/tfx_user_code_Trainer-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f-py3-none-any.whl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"train_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 5000,\\n  \\\"splits\\\": [\\n    \\\"train\\\"\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"SchemaGen\"\n",
      "upstream_nodes: \"Transform\"\n",
      "upstream_nodes: \"Tuner\"\n",
      "downstream_nodes: \"Evaluator\"\n",
      "downstream_nodes: \"Pusher\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "    enable_cache: true\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"sitomb-pipeline\"\n",
      ", pipeline_run_id='20240329-084051.264027', top_level_pipeline_run_id=None)\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "INFO:absl:udf_utils.get_fn {'custom_config': 'null', 'module_path': 'trainer@output/sitomb-pipeline/_wheels/tfx_user_code_Trainer-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f-py3-none-any.whl', 'eval_args': '{\\n  \"num_steps\": 1000,\\n  \"splits\": [\\n    \"eval\"\\n  ]\\n}', 'train_args': '{\\n  \"num_steps\": 5000,\\n  \"splits\": [\\n    \"train\"\\n  ]\\n}'} 'run_fn'\n",
      "INFO:absl:Installing 'output/sitomb-pipeline/_wheels/tfx_user_code_Trainer-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f-py3-none-any.whl' to a temporary directory.\n",
      "INFO:absl:Executing: ['/usr/bin/python3', '-m', 'pip', 'install', '--target', '/tmp/tmp5c4x68rn', 'output/sitomb-pipeline/_wheels/tfx_user_code_Trainer-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f-py3-none-any.whl']\n",
      "Processing ./output/sitomb-pipeline/_wheels/tfx_user_code_Trainer-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f-py3-none-any.whl\n",
      "Installing collected packages: tfx-user-code-Trainer\n",
      "Successfully installed tfx-user-code-Trainer-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f\n",
      "INFO:absl:Successfully installed 'output/sitomb-pipeline/_wheels/tfx_user_code_Trainer-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f-py3-none-any.whl'.\n",
      "INFO:absl:Training model.\n",
      "INFO:absl:Feature clickbait_xf has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature headline_xf has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature clickbait_xf has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature headline_xf has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "vectorize_layer_start\n",
      "Build_model_start\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " headline_xf (InputLayer)    [(None, 1)]               0         \n",
      "                                                                 \n",
      " tf.reshape (TFOpLambda)     (None,)                   0         \n",
      "                                                                 \n",
      " text_vectorization (TextVe  (None, 100)               0         \n",
      " ctorization)                                                    \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 100, 16)           160000    \n",
      "                                                                 \n",
      " global_average_pooling1d (  (None, 16)                0         \n",
      " GlobalAveragePooling1D)                                         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                1088      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 163201 (637.50 KB)\n",
      "Trainable params: 163201 (637.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " 995/1000 [============================>.] - ETA: 0s - loss: 0.1059 - binary_accuracy: 0.9627WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1000 batches). You may need to use the repeat() function when building your dataset.\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1000 batches). You may need to use the repeat() function when building your dataset.\n",
      "\n",
      "Epoch 1: val_binary_accuracy improved from -inf to 0.97130, saving model to output/sitomb-pipeline/Trainer/model/35/Format-Serving\n",
      "INFO:absl:Function `_wrapped_model` contains input name(s) table_handle, 69197, resource with unsupported characters which will be renamed to model_1_text_vectorization_string_lookup_none_lookup_lookuptablefindv2_table_handle, model_1_embedding_embedding_lookup_69197, model_1_dense_5_biasadd_readvariableop_resource in the SavedModel.\n",
      "INFO:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
      "INFO:absl:Writing fingerprint to output/sitomb-pipeline/Trainer/model/35/Format-Serving/fingerprint.pb\n",
      "1000/1000 [==============================] - 14s 12ms/step - loss: 0.1056 - binary_accuracy: 0.9628 - val_loss: 0.0809 - val_binary_accuracy: 0.9713\n",
      "Epoch 2/10\n",
      " 997/1000 [============================>.] - ETA: 0s - loss: 0.0287 - binary_accuracy: 0.9905WARNING:tensorflow:Early stopping conditioned on metric `val_binary_accuracy` which is not available. Available metrics are: loss,binary_accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_binary_accuracy` which is not available. Available metrics are: loss,binary_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_binary_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_binary_accuracy available, skipping.\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0287 - binary_accuracy: 0.9905\n",
      "Epoch 3/10\n",
      " 995/1000 [============================>.] - ETA: 0s - loss: 0.0188 - binary_accuracy: 0.9937WARNING:tensorflow:Early stopping conditioned on metric `val_binary_accuracy` which is not available. Available metrics are: loss,binary_accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_binary_accuracy` which is not available. Available metrics are: loss,binary_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_binary_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_binary_accuracy available, skipping.\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0188 - binary_accuracy: 0.9938\n",
      "Epoch 4/10\n",
      " 994/1000 [============================>.] - ETA: 0s - loss: 0.0150 - binary_accuracy: 0.9945WARNING:tensorflow:Early stopping conditioned on metric `val_binary_accuracy` which is not available. Available metrics are: loss,binary_accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_binary_accuracy` which is not available. Available metrics are: loss,binary_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_binary_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_binary_accuracy available, skipping.\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0150 - binary_accuracy: 0.9945\n",
      "Epoch 5/10\n",
      "  15/1000 [..............................] - ETA: 7s - loss: 0.0082 - binary_accuracy: 0.9957WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_binary_accuracy` which is not available. Available metrics are: loss,binary_accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_binary_accuracy` which is not available. Available metrics are: loss,binary_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_binary_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_binary_accuracy available, skipping.\n",
      "1000/1000 [==============================] - 0s 120us/step - loss: 0.0082 - binary_accuracy: 0.9957\n",
      "INFO:absl:Feature clickbait has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature headline has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Function `serve_tf_examples_fn` contains input name(s) table_handle, 154892, resource with unsupported characters which will be renamed to model_1_text_vectorization_string_lookup_hash_table_lookup_lookuptablefindv2_table_handle, model_1_embedding_embedding_lookup_154892, model_1_dense_5_biasadd_readvariableop_resource in the SavedModel.\n",
      "INFO:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
      "INFO:absl:Writing fingerprint to output/sitomb-pipeline/Trainer/model/35/Format-Serving/fingerprint.pb\n",
      "INFO:absl:Training complete. Model written to output/sitomb-pipeline/Trainer/model/35/Format-Serving. ModelRun written to output/sitomb-pipeline/Trainer/model_run/35\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 35 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'model_run': [Artifact(artifact: uri: \"output/sitomb-pipeline/Trainer/model_run/35\"\n",
      ", artifact_type: name: \"ModelRun\"\n",
      ")], 'model': [Artifact(artifact: uri: \"output/sitomb-pipeline/Trainer/model/35\"\n",
      ", artifact_type: name: \"Model\"\n",
      "base_type: MODEL\n",
      ")]}) for execution 35\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:node Trainer is finished.\n",
      "INFO:absl:node Evaluator is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.evaluator.component.Evaluator\"\n",
      "    base_type: EVALUATE\n",
      "  }\n",
      "  id: \"Evaluator\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"sitomb-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"20240329-084051.264027\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"sitomb-pipeline.Evaluator\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"baseline_model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Latest_blessed_model_resolver\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20240329-084051.264027\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline.Latest_blessed_model_resolver\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"CsvExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20240329-084051.264027\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline.CsvExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Trainer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20240329-084051.264027\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline.Trainer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"blessing\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelBlessing\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"evaluation\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelEvaluation\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"eval_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"metrics_specs\\\": [\\n    {\\n      \\\"metrics\\\": [\\n        {\\n          \\\"class_name\\\": \\\"AUC\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"Precision\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"Recall\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"ExampleCount\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"BinaryAccuracy\\\",\\n          \\\"threshold\\\": {\\n            \\\"change_threshold\\\": {\\n              \\\"absolute\\\": 0.0001,\\n              \\\"direction\\\": \\\"HIGHER_IS_BETTER\\\"\\n            },\\n            \\\"value_threshold\\\": {\\n              \\\"lower_bound\\\": 0.5\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \\\"model_specs\\\": [\\n    {\\n      \\\"label_key\\\": \\\"clickbait\\\"\\n    }\\n  ],\\n  \\\"slicing_specs\\\": [\\n    {},\\n    {\\n      \\\"feature_keys\\\": [\\n        \\\"h\\\",\\n        \\\"e\\\",\\n        \\\"a\\\",\\n        \\\"d\\\",\\n        \\\"l\\\",\\n        \\\"i\\\",\\n        \\\"n\\\",\\n        \\\"e\\\"\\n      ]\\n    }\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"example_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"fairness_indicator_thresholds\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"CsvExampleGen\"\n",
      "upstream_nodes: \"Latest_blessed_model_resolver\"\n",
      "upstream_nodes: \"Trainer\"\n",
      "downstream_nodes: \"Pusher\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "    enable_cache: true\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "INFO:absl:[Evaluator] Resolved inputs: ({'model': [Artifact(artifact: id: 34\n",
      "type_id: 31\n",
      "uri: \"output/sitomb-pipeline/Trainer/model/35\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.14.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Model\"\n",
      "create_time_since_epoch: 1711701803968\n",
      "last_update_time_since_epoch: 1711701803968\n",
      ", artifact_type: id: 31\n",
      "name: \"Model\"\n",
      "base_type: MODEL\n",
      ")], 'examples': [Artifact(artifact: id: 1\n",
      "type_id: 16\n",
      "uri: \"output/sitomb-pipeline/CsvExampleGen/examples/2\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"file_format\"\n",
      "  value {\n",
      "    string_value: \"tfrecords_gzip\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"input_fingerprint\"\n",
      "  value {\n",
      "    string_value: \"split:single_split,num_files:1,total_bytes:1835039,xor_checksum:1711592832,sum_checksum:1711592832\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"payload_format\"\n",
      "  value {\n",
      "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.14.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Examples\"\n",
      "create_time_since_epoch: 1711698900986\n",
      "last_update_time_since_epoch: 1711698900986\n",
      ", artifact_type: id: 16\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")], 'baseline_model': []},)\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 36\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=36, input_dict={'model': [Artifact(artifact: id: 34\n",
      "type_id: 31\n",
      "uri: \"output/sitomb-pipeline/Trainer/model/35\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.14.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Model\"\n",
      "create_time_since_epoch: 1711701803968\n",
      "last_update_time_since_epoch: 1711701803968\n",
      ", artifact_type: id: 31\n",
      "name: \"Model\"\n",
      "base_type: MODEL\n",
      ")], 'examples': [Artifact(artifact: id: 1\n",
      "type_id: 16\n",
      "uri: \"output/sitomb-pipeline/CsvExampleGen/examples/2\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"file_format\"\n",
      "  value {\n",
      "    string_value: \"tfrecords_gzip\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"input_fingerprint\"\n",
      "  value {\n",
      "    string_value: \"split:single_split,num_files:1,total_bytes:1835039,xor_checksum:1711592832,sum_checksum:1711592832\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"payload_format\"\n",
      "  value {\n",
      "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.14.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Examples\"\n",
      "create_time_since_epoch: 1711698900986\n",
      "last_update_time_since_epoch: 1711698900986\n",
      ", artifact_type: id: 16\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")], 'baseline_model': []}, output_dict=defaultdict(<class 'list'>, {'evaluation': [Artifact(artifact: uri: \"output/sitomb-pipeline/Evaluator/evaluation/36\"\n",
      ", artifact_type: name: \"ModelEvaluation\"\n",
      ")], 'blessing': [Artifact(artifact: uri: \"output/sitomb-pipeline/Evaluator/blessing/36\"\n",
      ", artifact_type: name: \"ModelBlessing\"\n",
      ")]}), exec_properties={'example_splits': 'null', 'eval_config': '{\\n  \"metrics_specs\": [\\n    {\\n      \"metrics\": [\\n        {\\n          \"class_name\": \"AUC\"\\n        },\\n        {\\n          \"class_name\": \"Precision\"\\n        },\\n        {\\n          \"class_name\": \"Recall\"\\n        },\\n        {\\n          \"class_name\": \"ExampleCount\"\\n        },\\n        {\\n          \"class_name\": \"BinaryAccuracy\",\\n          \"threshold\": {\\n            \"change_threshold\": {\\n              \"absolute\": 0.0001,\\n              \"direction\": \"HIGHER_IS_BETTER\"\\n            },\\n            \"value_threshold\": {\\n              \"lower_bound\": 0.5\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \"model_specs\": [\\n    {\\n      \"label_key\": \"clickbait\"\\n    }\\n  ],\\n  \"slicing_specs\": [\\n    {},\\n    {\\n      \"feature_keys\": [\\n        \"h\",\\n        \"e\",\\n        \"a\",\\n        \"d\",\\n        \"l\",\\n        \"i\",\\n        \"n\",\\n        \"e\"\\n      ]\\n    }\\n  ]\\n}', 'fairness_indicator_thresholds': 'null'}, execution_output_uri='output/sitomb-pipeline/Evaluator/.system/executor_execution/36/executor_output.pb', stateful_working_dir='output/sitomb-pipeline/Evaluator/.system/stateful_working_dir/20240329-084051.264027', tmp_dir='output/sitomb-pipeline/Evaluator/.system/executor_execution/36/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.evaluator.component.Evaluator\"\n",
      "    base_type: EVALUATE\n",
      "  }\n",
      "  id: \"Evaluator\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"sitomb-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"20240329-084051.264027\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"sitomb-pipeline.Evaluator\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"baseline_model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Latest_blessed_model_resolver\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20240329-084051.264027\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline.Latest_blessed_model_resolver\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"CsvExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20240329-084051.264027\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline.CsvExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Trainer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20240329-084051.264027\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline.Trainer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"blessing\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelBlessing\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"evaluation\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelEvaluation\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"eval_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"metrics_specs\\\": [\\n    {\\n      \\\"metrics\\\": [\\n        {\\n          \\\"class_name\\\": \\\"AUC\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"Precision\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"Recall\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"ExampleCount\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"BinaryAccuracy\\\",\\n          \\\"threshold\\\": {\\n            \\\"change_threshold\\\": {\\n              \\\"absolute\\\": 0.0001,\\n              \\\"direction\\\": \\\"HIGHER_IS_BETTER\\\"\\n            },\\n            \\\"value_threshold\\\": {\\n              \\\"lower_bound\\\": 0.5\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \\\"model_specs\\\": [\\n    {\\n      \\\"label_key\\\": \\\"clickbait\\\"\\n    }\\n  ],\\n  \\\"slicing_specs\\\": [\\n    {},\\n    {\\n      \\\"feature_keys\\\": [\\n        \\\"h\\\",\\n        \\\"e\\\",\\n        \\\"a\\\",\\n        \\\"d\\\",\\n        \\\"l\\\",\\n        \\\"i\\\",\\n        \\\"n\\\",\\n        \\\"e\\\"\\n      ]\\n    }\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"example_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"fairness_indicator_thresholds\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"CsvExampleGen\"\n",
      "upstream_nodes: \"Latest_blessed_model_resolver\"\n",
      "upstream_nodes: \"Trainer\"\n",
      "downstream_nodes: \"Pusher\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "    enable_cache: true\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"sitomb-pipeline\"\n",
      ", pipeline_run_id='20240329-084051.264027', top_level_pipeline_run_id=None)\n",
      "INFO:absl:udf_utils.get_fn {'example_splits': 'null', 'eval_config': '{\\n  \"metrics_specs\": [\\n    {\\n      \"metrics\": [\\n        {\\n          \"class_name\": \"AUC\"\\n        },\\n        {\\n          \"class_name\": \"Precision\"\\n        },\\n        {\\n          \"class_name\": \"Recall\"\\n        },\\n        {\\n          \"class_name\": \"ExampleCount\"\\n        },\\n        {\\n          \"class_name\": \"BinaryAccuracy\",\\n          \"threshold\": {\\n            \"change_threshold\": {\\n              \"absolute\": 0.0001,\\n              \"direction\": \"HIGHER_IS_BETTER\"\\n            },\\n            \"value_threshold\": {\\n              \"lower_bound\": 0.5\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \"model_specs\": [\\n    {\\n      \"label_key\": \"clickbait\"\\n    }\\n  ],\\n  \"slicing_specs\": [\\n    {},\\n    {\\n      \"feature_keys\": [\\n        \"h\",\\n        \"e\",\\n        \"a\",\\n        \"d\",\\n        \"l\",\\n        \"i\",\\n        \"n\",\\n        \"e\"\\n      ]\\n    }\\n  ]\\n}', 'fairness_indicator_thresholds': 'null'} 'custom_eval_shared_model'\n",
      "INFO:absl:Request was made to ignore the baseline ModelSpec and any change thresholds. This is likely because a baseline model was not provided: updated_config=\n",
      "model_specs {\n",
      "  label_key: \"clickbait\"\n",
      "}\n",
      "slicing_specs {\n",
      "}\n",
      "slicing_specs {\n",
      "  feature_keys: \"h\"\n",
      "  feature_keys: \"e\"\n",
      "  feature_keys: \"a\"\n",
      "  feature_keys: \"d\"\n",
      "  feature_keys: \"l\"\n",
      "  feature_keys: \"i\"\n",
      "  feature_keys: \"n\"\n",
      "  feature_keys: \"e\"\n",
      "}\n",
      "metrics_specs {\n",
      "  metrics {\n",
      "    class_name: \"AUC\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"Precision\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"Recall\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"ExampleCount\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"BinaryAccuracy\"\n",
      "    threshold {\n",
      "      value_threshold {\n",
      "        lower_bound {\n",
      "          value: 0.5\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:Using output/sitomb-pipeline/Trainer/model/35/Format-Serving as  model.\n",
      "INFO:absl:The 'example_splits' parameter is not set, using 'eval' split.\n",
      "INFO:absl:Evaluating model.\n",
      "INFO:absl:udf_utils.get_fn {'example_splits': 'null', 'eval_config': '{\\n  \"metrics_specs\": [\\n    {\\n      \"metrics\": [\\n        {\\n          \"class_name\": \"AUC\"\\n        },\\n        {\\n          \"class_name\": \"Precision\"\\n        },\\n        {\\n          \"class_name\": \"Recall\"\\n        },\\n        {\\n          \"class_name\": \"ExampleCount\"\\n        },\\n        {\\n          \"class_name\": \"BinaryAccuracy\",\\n          \"threshold\": {\\n            \"change_threshold\": {\\n              \"absolute\": 0.0001,\\n              \"direction\": \"HIGHER_IS_BETTER\"\\n            },\\n            \"value_threshold\": {\\n              \"lower_bound\": 0.5\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \"model_specs\": [\\n    {\\n      \"label_key\": \"clickbait\"\\n    }\\n  ],\\n  \"slicing_specs\": [\\n    {},\\n    {\\n      \"feature_keys\": [\\n        \"h\",\\n        \"e\",\\n        \"a\",\\n        \"d\",\\n        \"l\",\\n        \"i\",\\n        \"n\",\\n        \"e\"\\n      ]\\n    }\\n  ]\\n}', 'fairness_indicator_thresholds': 'null'} 'custom_extractors'\n",
      "INFO:absl:Request was made to ignore the baseline ModelSpec and any change thresholds. This is likely because a baseline model was not provided: updated_config=\n",
      "model_specs {\n",
      "  label_key: \"clickbait\"\n",
      "}\n",
      "slicing_specs {\n",
      "}\n",
      "slicing_specs {\n",
      "  feature_keys: \"h\"\n",
      "  feature_keys: \"e\"\n",
      "  feature_keys: \"a\"\n",
      "  feature_keys: \"d\"\n",
      "  feature_keys: \"l\"\n",
      "  feature_keys: \"i\"\n",
      "  feature_keys: \"n\"\n",
      "  feature_keys: \"e\"\n",
      "}\n",
      "metrics_specs {\n",
      "  metrics {\n",
      "    class_name: \"AUC\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"Precision\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"Recall\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"ExampleCount\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"BinaryAccuracy\"\n",
      "    threshold {\n",
      "      value_threshold {\n",
      "        lower_bound {\n",
      "          value: 0.5\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  model_names: \"\"\n",
      "}\n",
      "\n",
      "INFO:absl:Request was made to ignore the baseline ModelSpec and any change thresholds. This is likely because a baseline model was not provided: updated_config=\n",
      "model_specs {\n",
      "  label_key: \"clickbait\"\n",
      "}\n",
      "slicing_specs {\n",
      "}\n",
      "slicing_specs {\n",
      "  feature_keys: \"h\"\n",
      "  feature_keys: \"e\"\n",
      "  feature_keys: \"a\"\n",
      "  feature_keys: \"d\"\n",
      "  feature_keys: \"l\"\n",
      "  feature_keys: \"i\"\n",
      "  feature_keys: \"n\"\n",
      "  feature_keys: \"e\"\n",
      "}\n",
      "metrics_specs {\n",
      "  metrics {\n",
      "    class_name: \"AUC\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"Precision\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"Recall\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"ExampleCount\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"BinaryAccuracy\"\n",
      "    threshold {\n",
      "      value_threshold {\n",
      "        lower_bound {\n",
      "          value: 0.5\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  model_names: \"\"\n",
      "}\n",
      "\n",
      "INFO:absl:eval_shared_models have model_types: {'tf_keras'}\n",
      "INFO:absl:Request was made to ignore the baseline ModelSpec and any change thresholds. This is likely because a baseline model was not provided: updated_config=\n",
      "model_specs {\n",
      "  label_key: \"clickbait\"\n",
      "}\n",
      "slicing_specs {\n",
      "}\n",
      "slicing_specs {\n",
      "  feature_keys: \"h\"\n",
      "  feature_keys: \"e\"\n",
      "  feature_keys: \"a\"\n",
      "  feature_keys: \"d\"\n",
      "  feature_keys: \"l\"\n",
      "  feature_keys: \"i\"\n",
      "  feature_keys: \"n\"\n",
      "  feature_keys: \"e\"\n",
      "}\n",
      "metrics_specs {\n",
      "  metrics {\n",
      "    class_name: \"AUC\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"Precision\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"Recall\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"ExampleCount\"\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"BinaryAccuracy\"\n",
      "    threshold {\n",
      "      value_threshold {\n",
      "        lower_bound {\n",
      "          value: 0.5\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  model_names: \"\"\n",
      "}\n",
      "\n",
      "INFO:absl:Evaluation complete. Results written to output/sitomb-pipeline/Evaluator/evaluation/36.\n",
      "INFO:absl:Checking validation results.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow_model_analysis/writers/metrics_plots_and_validations_writer.py:111: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow_model_analysis/writers/metrics_plots_and_validations_writer.py:111: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "INFO:absl:Blessing result True written to output/sitomb-pipeline/Evaluator/blessing/36.\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 36 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'evaluation': [Artifact(artifact: uri: \"output/sitomb-pipeline/Evaluator/evaluation/36\"\n",
      ", artifact_type: name: \"ModelEvaluation\"\n",
      ")], 'blessing': [Artifact(artifact: uri: \"output/sitomb-pipeline/Evaluator/blessing/36\"\n",
      ", artifact_type: name: \"ModelBlessing\"\n",
      ")]}) for execution 36\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:node Evaluator is finished.\n",
      "INFO:absl:node Pusher is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.pusher.component.Pusher\"\n",
      "    base_type: DEPLOY\n",
      "  }\n",
      "  id: \"Pusher\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"sitomb-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"20240329-084051.264027\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"sitomb-pipeline.Pusher\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Trainer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20240329-084051.264027\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline.Trainer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"model_blessing\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Evaluator\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20240329-084051.264027\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline.Evaluator\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"ModelBlessing\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"blessing\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"pushed_model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"PushedModel\"\n",
      "          base_type: MODEL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"push_destination\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"filesystem\\\": {\\n    \\\"base_directory\\\": \\\"output/serving_model\\\"\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"Evaluator\"\n",
      "upstream_nodes: \"Trainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "    enable_cache: true\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "INFO:absl:[Pusher] Resolved inputs: ({'model_blessing': [Artifact(artifact: id: 36\n",
      "type_id: 34\n",
      "uri: \"output/sitomb-pipeline/Evaluator/blessing/36\"\n",
      "custom_properties {\n",
      "  key: \"blessed\"\n",
      "  value {\n",
      "    int_value: 1\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"current_model\"\n",
      "  value {\n",
      "    string_value: \"output/sitomb-pipeline/Trainer/model/35\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"current_model_id\"\n",
      "  value {\n",
      "    int_value: 34\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.14.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"ModelBlessing\"\n",
      "create_time_since_epoch: 1711701816167\n",
      "last_update_time_since_epoch: 1711701816167\n",
      ", artifact_type: id: 34\n",
      "name: \"ModelBlessing\"\n",
      ")], 'model': [Artifact(artifact: id: 34\n",
      "type_id: 31\n",
      "uri: \"output/sitomb-pipeline/Trainer/model/35\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.14.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Model\"\n",
      "create_time_since_epoch: 1711701803968\n",
      "last_update_time_since_epoch: 1711701803968\n",
      ", artifact_type: id: 31\n",
      "name: \"Model\"\n",
      "base_type: MODEL\n",
      ")]},)\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 37\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=37, input_dict={'model_blessing': [Artifact(artifact: id: 36\n",
      "type_id: 34\n",
      "uri: \"output/sitomb-pipeline/Evaluator/blessing/36\"\n",
      "custom_properties {\n",
      "  key: \"blessed\"\n",
      "  value {\n",
      "    int_value: 1\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"current_model\"\n",
      "  value {\n",
      "    string_value: \"output/sitomb-pipeline/Trainer/model/35\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"current_model_id\"\n",
      "  value {\n",
      "    int_value: 34\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.14.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"ModelBlessing\"\n",
      "create_time_since_epoch: 1711701816167\n",
      "last_update_time_since_epoch: 1711701816167\n",
      ", artifact_type: id: 34\n",
      "name: \"ModelBlessing\"\n",
      ")], 'model': [Artifact(artifact: id: 34\n",
      "type_id: 31\n",
      "uri: \"output/sitomb-pipeline/Trainer/model/35\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.14.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Model\"\n",
      "create_time_since_epoch: 1711701803968\n",
      "last_update_time_since_epoch: 1711701803968\n",
      ", artifact_type: id: 31\n",
      "name: \"Model\"\n",
      "base_type: MODEL\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'pushed_model': [Artifact(artifact: uri: \"output/sitomb-pipeline/Pusher/pushed_model/37\"\n",
      ", artifact_type: name: \"PushedModel\"\n",
      "base_type: MODEL\n",
      ")]}), exec_properties={'custom_config': 'null', 'push_destination': '{\\n  \"filesystem\": {\\n    \"base_directory\": \"output/serving_model\"\\n  }\\n}'}, execution_output_uri='output/sitomb-pipeline/Pusher/.system/executor_execution/37/executor_output.pb', stateful_working_dir='output/sitomb-pipeline/Pusher/.system/stateful_working_dir/20240329-084051.264027', tmp_dir='output/sitomb-pipeline/Pusher/.system/executor_execution/37/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.pusher.component.Pusher\"\n",
      "    base_type: DEPLOY\n",
      "  }\n",
      "  id: \"Pusher\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"sitomb-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"20240329-084051.264027\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"sitomb-pipeline.Pusher\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Trainer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20240329-084051.264027\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline.Trainer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"model_blessing\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Evaluator\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"20240329-084051.264027\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"sitomb-pipeline.Evaluator\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"ModelBlessing\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"blessing\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"pushed_model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"PushedModel\"\n",
      "          base_type: MODEL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"push_destination\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"filesystem\\\": {\\n    \\\"base_directory\\\": \\\"output/serving_model\\\"\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"Evaluator\"\n",
      "upstream_nodes: \"Trainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "    enable_cache: true\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"sitomb-pipeline\"\n",
      ", pipeline_run_id='20240329-084051.264027', top_level_pipeline_run_id=None)\n",
      "INFO:absl:Model version: 1711701816\n",
      "INFO:absl:Model written to serving path output/serving_model/1711701816.\n",
      "INFO:absl:Model pushed to output/sitomb-pipeline/Pusher/pushed_model/37.\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 37 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'pushed_model': [Artifact(artifact: uri: \"output/sitomb-pipeline/Pusher/pushed_model/37\"\n",
      ", artifact_type: name: \"PushedModel\"\n",
      "base_type: MODEL\n",
      ")]}) for execution 37\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:node Pusher is finished.\n",
      "--- 187.16135096549988 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "!python local_pipeline.py\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "hT0PHr_UXNd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34;42m.\u001b[0m\n",
      "├── \u001b[34;42mconfig\u001b[0m\n",
      "│   └── \u001b[01;32mprometheus.config\u001b[0m\n",
      "├── \u001b[34;42mdataset\u001b[0m\n",
      "│   └── \u001b[01;32mclickbait.csv\u001b[0m\n",
      "├── \u001b[01;32mDockerfile\u001b[0m\n",
      "├── \u001b[01;32mlocal_pipeline.py\u001b[0m\n",
      "├── \u001b[01;32mmain_run_local_pipeline_clickbait.ipynb\u001b[0m\n",
      "├── \u001b[34;42mmodules\u001b[0m\n",
      "│   ├── \u001b[01;32mcomponents.py\u001b[0m\n",
      "│   ├── \u001b[01;32mtrainer.py\u001b[0m\n",
      "│   ├── \u001b[01;32mtransform.py\u001b[0m\n",
      "│   └── \u001b[01;32mtuner.py\u001b[0m\n",
      "├── \u001b[34;42mmonitoring\u001b[0m\n",
      "│   ├── \u001b[01;32mDockerfile\u001b[0m\n",
      "│   └── \u001b[01;32mprometheus.yml\u001b[0m\n",
      "├── \u001b[34;42moutput\u001b[0m\n",
      "│   ├── \u001b[34;42mserving_model\u001b[0m\n",
      "│   │   └── \u001b[34;42m1711701816\u001b[0m\n",
      "│   │       ├── \u001b[34;42massets\u001b[0m\n",
      "│   │       ├── \u001b[01;32mfingerprint.pb\u001b[0m\n",
      "│   │       ├── \u001b[01;32mkeras_metadata.pb\u001b[0m\n",
      "│   │       ├── \u001b[01;32msaved_model.pb\u001b[0m\n",
      "│   │       └── \u001b[34;42mvariables\u001b[0m\n",
      "│   │           ├── \u001b[01;32mvariables.data-00000-of-00001\u001b[0m\n",
      "│   │           └── \u001b[01;32mvariables.index\u001b[0m\n",
      "│   └── \u001b[34;42msitomb-pipeline\u001b[0m\n",
      "│       ├── \u001b[34;42mCsvExampleGen\u001b[0m\n",
      "│       │   └── \u001b[34;42mexamples\u001b[0m\n",
      "│       │       └── \u001b[34;42m2\u001b[0m\n",
      "│       │           ├── \u001b[34;42mSplit-eval\u001b[0m\n",
      "│       │           │   └── \u001b[01;32mdata_tfrecord-00000-of-00001.gz\u001b[0m\n",
      "│       │           └── \u001b[34;42mSplit-train\u001b[0m\n",
      "│       │               └── \u001b[01;32mdata_tfrecord-00000-of-00001.gz\u001b[0m\n",
      "│       ├── \u001b[34;42mEvaluator\u001b[0m\n",
      "│       │   ├── \u001b[34;42mblessing\u001b[0m\n",
      "│       │   │   └── \u001b[34;42m36\u001b[0m\n",
      "│       │   │       └── \u001b[01;32mBLESSED\u001b[0m\n",
      "│       │   └── \u001b[34;42mevaluation\u001b[0m\n",
      "│       │       └── \u001b[34;42m36\u001b[0m\n",
      "│       │           ├── \u001b[01;32mattributions-00000-of-00001.tfrecord\u001b[0m\n",
      "│       │           ├── \u001b[01;32meval_config.json\u001b[0m\n",
      "│       │           ├── \u001b[01;32mmetrics-00000-of-00001.tfrecord\u001b[0m\n",
      "│       │           ├── \u001b[01;32mplots-00000-of-00001.tfrecord\u001b[0m\n",
      "│       │           └── \u001b[01;32mvalidations.tfrecord\u001b[0m\n",
      "│       ├── \u001b[34;42mExampleValidator\u001b[0m\n",
      "│       │   └── \u001b[34;42manomalies\u001b[0m\n",
      "│       │       └── \u001b[34;42m6\u001b[0m\n",
      "│       │           ├── \u001b[34;42mSplit-eval\u001b[0m\n",
      "│       │           │   └── \u001b[01;32mSchemaDiff.pb\u001b[0m\n",
      "│       │           └── \u001b[34;42mSplit-train\u001b[0m\n",
      "│       │               └── \u001b[01;32mSchemaDiff.pb\u001b[0m\n",
      "│       ├── \u001b[01;32mmetadata.sqlite\u001b[0m\n",
      "│       ├── \u001b[34;42mPusher\u001b[0m\n",
      "│       │   └── \u001b[34;42mpushed_model\u001b[0m\n",
      "│       │       └── \u001b[34;42m37\u001b[0m\n",
      "│       │           ├── \u001b[34;42massets\u001b[0m\n",
      "│       │           ├── \u001b[01;32mfingerprint.pb\u001b[0m\n",
      "│       │           ├── \u001b[01;32mkeras_metadata.pb\u001b[0m\n",
      "│       │           ├── \u001b[01;32msaved_model.pb\u001b[0m\n",
      "│       │           └── \u001b[34;42mvariables\u001b[0m\n",
      "│       │               ├── \u001b[01;32mvariables.data-00000-of-00001\u001b[0m\n",
      "│       │               └── \u001b[01;32mvariables.index\u001b[0m\n",
      "│       ├── \u001b[34;42mSchemaGen\u001b[0m\n",
      "│       │   └── \u001b[34;42mschema\u001b[0m\n",
      "│       │       └── \u001b[34;42m4\u001b[0m\n",
      "│       │           └── \u001b[01;32mschema.pbtxt\u001b[0m\n",
      "│       ├── \u001b[34;42mStatisticsGen\u001b[0m\n",
      "│       │   └── \u001b[34;42mstatistics\u001b[0m\n",
      "│       │       └── \u001b[34;42m3\u001b[0m\n",
      "│       │           ├── \u001b[34;42mSplit-eval\u001b[0m\n",
      "│       │           │   └── \u001b[01;32mFeatureStats.pb\u001b[0m\n",
      "│       │           └── \u001b[34;42mSplit-train\u001b[0m\n",
      "│       │               └── \u001b[01;32mFeatureStats.pb\u001b[0m\n",
      "│       ├── \u001b[34;42mTrainer\u001b[0m\n",
      "│       │   ├── \u001b[34;42mmodel\u001b[0m\n",
      "│       │   │   └── \u001b[34;42m35\u001b[0m\n",
      "│       │   │       ├── \u001b[34;42mFormat-Serving\u001b[0m\n",
      "│       │   │       │   ├── \u001b[34;42massets\u001b[0m\n",
      "│       │   │       │   ├── \u001b[01;32mfingerprint.pb\u001b[0m\n",
      "│       │   │       │   ├── \u001b[01;32mkeras_metadata.pb\u001b[0m\n",
      "│       │   │       │   ├── \u001b[01;32msaved_model.pb\u001b[0m\n",
      "│       │   │       │   └── \u001b[34;42mvariables\u001b[0m\n",
      "│       │   │       │       ├── \u001b[01;32mvariables.data-00000-of-00001\u001b[0m\n",
      "│       │   │       │       └── \u001b[01;32mvariables.index\u001b[0m\n",
      "│       │   │       └── \u001b[34;42mlogs\u001b[0m\n",
      "│       │   │           ├── \u001b[34;42mtrain\u001b[0m\n",
      "│       │   │           │   └── \u001b[01;32mevents.out.tfevents.1711701758.b6b1159d2989.26705.0.v2\u001b[0m\n",
      "│       │   │           └── \u001b[34;42mvalidation\u001b[0m\n",
      "│       │   │               └── \u001b[01;32mevents.out.tfevents.1711701768.b6b1159d2989.26705.1.v2\u001b[0m\n",
      "│       │   └── \u001b[34;42mmodel_run\u001b[0m\n",
      "│       │       └── \u001b[34;42m35\u001b[0m\n",
      "│       ├── \u001b[34;42mTransform\u001b[0m\n",
      "│       │   ├── \u001b[34;42mpost_transform_anomalies\u001b[0m\n",
      "│       │   │   ├── \u001b[34;42m13\u001b[0m\n",
      "│       │   │   │   └── \u001b[01;32mSchemaDiff.pb\u001b[0m\n",
      "│       │   │   ├── \u001b[34;42m27\u001b[0m\n",
      "│       │   │   ├── \u001b[34;42m33\u001b[0m\n",
      "│       │   │   │   └── \u001b[01;32mSchemaDiff.pb\u001b[0m\n",
      "│       │   │   └── \u001b[34;42m5\u001b[0m\n",
      "│       │   │       └── \u001b[01;32mSchemaDiff.pb\u001b[0m\n",
      "│       │   ├── \u001b[34;42mpost_transform_schema\u001b[0m\n",
      "│       │   │   ├── \u001b[34;42m13\u001b[0m\n",
      "│       │   │   │   └── \u001b[01;32mschema.pbtxt\u001b[0m\n",
      "│       │   │   ├── \u001b[34;42m27\u001b[0m\n",
      "│       │   │   ├── \u001b[34;42m33\u001b[0m\n",
      "│       │   │   │   └── \u001b[01;32mschema.pbtxt\u001b[0m\n",
      "│       │   │   └── \u001b[34;42m5\u001b[0m\n",
      "│       │   │       └── \u001b[01;32mschema.pbtxt\u001b[0m\n",
      "│       │   ├── \u001b[34;42mpost_transform_stats\u001b[0m\n",
      "│       │   │   ├── \u001b[34;42m13\u001b[0m\n",
      "│       │   │   │   └── \u001b[01;32mFeatureStats.pb\u001b[0m\n",
      "│       │   │   ├── \u001b[34;42m27\u001b[0m\n",
      "│       │   │   ├── \u001b[34;42m33\u001b[0m\n",
      "│       │   │   │   └── \u001b[01;32mFeatureStats.pb\u001b[0m\n",
      "│       │   │   └── \u001b[34;42m5\u001b[0m\n",
      "│       │   │       └── \u001b[01;32mFeatureStats.pb\u001b[0m\n",
      "│       │   ├── \u001b[34;42mpre_transform_schema\u001b[0m\n",
      "│       │   │   ├── \u001b[34;42m13\u001b[0m\n",
      "│       │   │   │   └── \u001b[01;32mschema.pbtxt\u001b[0m\n",
      "│       │   │   ├── \u001b[34;42m27\u001b[0m\n",
      "│       │   │   ├── \u001b[34;42m33\u001b[0m\n",
      "│       │   │   │   └── \u001b[01;32mschema.pbtxt\u001b[0m\n",
      "│       │   │   └── \u001b[34;42m5\u001b[0m\n",
      "│       │   │       └── \u001b[01;32mschema.pbtxt\u001b[0m\n",
      "│       │   ├── \u001b[34;42mpre_transform_stats\u001b[0m\n",
      "│       │   │   ├── \u001b[34;42m13\u001b[0m\n",
      "│       │   │   │   └── \u001b[01;32mFeatureStats.pb\u001b[0m\n",
      "│       │   │   ├── \u001b[34;42m27\u001b[0m\n",
      "│       │   │   ├── \u001b[34;42m33\u001b[0m\n",
      "│       │   │   │   └── \u001b[01;32mFeatureStats.pb\u001b[0m\n",
      "│       │   │   └── \u001b[34;42m5\u001b[0m\n",
      "│       │   │       └── \u001b[01;32mFeatureStats.pb\u001b[0m\n",
      "│       │   ├── \u001b[34;42mtransformed_examples\u001b[0m\n",
      "│       │   │   ├── \u001b[34;42m13\u001b[0m\n",
      "│       │   │   │   ├── \u001b[34;42mSplit-eval\u001b[0m\n",
      "│       │   │   │   │   └── \u001b[01;32mtransformed_examples-00000-of-00001.gz\u001b[0m\n",
      "│       │   │   │   └── \u001b[34;42mSplit-train\u001b[0m\n",
      "│       │   │   │       └── \u001b[01;32mtransformed_examples-00000-of-00001.gz\u001b[0m\n",
      "│       │   │   ├── \u001b[34;42m27\u001b[0m\n",
      "│       │   │   ├── \u001b[34;42m33\u001b[0m\n",
      "│       │   │   │   ├── \u001b[34;42mSplit-eval\u001b[0m\n",
      "│       │   │   │   │   └── \u001b[01;32mtransformed_examples-00000-of-00001.gz\u001b[0m\n",
      "│       │   │   │   └── \u001b[34;42mSplit-train\u001b[0m\n",
      "│       │   │   │       └── \u001b[01;32mtransformed_examples-00000-of-00001.gz\u001b[0m\n",
      "│       │   │   └── \u001b[34;42m5\u001b[0m\n",
      "│       │   │       ├── \u001b[34;42mSplit-eval\u001b[0m\n",
      "│       │   │       │   └── \u001b[01;32mtransformed_examples-00000-of-00001.gz\u001b[0m\n",
      "│       │   │       └── \u001b[34;42mSplit-train\u001b[0m\n",
      "│       │   │           └── \u001b[01;32mtransformed_examples-00000-of-00001.gz\u001b[0m\n",
      "│       │   ├── \u001b[34;42mtransform_graph\u001b[0m\n",
      "│       │   │   ├── \u001b[34;42m13\u001b[0m\n",
      "│       │   │   │   ├── \u001b[34;42mmetadata\u001b[0m\n",
      "│       │   │   │   │   └── \u001b[01;32mschema.pbtxt\u001b[0m\n",
      "│       │   │   │   ├── \u001b[34;42mtransformed_metadata\u001b[0m\n",
      "│       │   │   │   │   └── \u001b[01;32mschema.pbtxt\u001b[0m\n",
      "│       │   │   │   └── \u001b[34;42mtransform_fn\u001b[0m\n",
      "│       │   │   │       ├── \u001b[34;42massets\u001b[0m\n",
      "│       │   │   │       ├── \u001b[01;32mfingerprint.pb\u001b[0m\n",
      "│       │   │   │       ├── \u001b[01;32msaved_model.pb\u001b[0m\n",
      "│       │   │   │       └── \u001b[34;42mvariables\u001b[0m\n",
      "│       │   │   │           ├── \u001b[01;32mvariables.data-00000-of-00001\u001b[0m\n",
      "│       │   │   │           └── \u001b[01;32mvariables.index\u001b[0m\n",
      "│       │   │   ├── \u001b[34;42m27\u001b[0m\n",
      "│       │   │   ├── \u001b[34;42m33\u001b[0m\n",
      "│       │   │   │   ├── \u001b[34;42mmetadata\u001b[0m\n",
      "│       │   │   │   │   └── \u001b[01;32mschema.pbtxt\u001b[0m\n",
      "│       │   │   │   ├── \u001b[34;42mtransformed_metadata\u001b[0m\n",
      "│       │   │   │   │   └── \u001b[01;32mschema.pbtxt\u001b[0m\n",
      "│       │   │   │   └── \u001b[34;42mtransform_fn\u001b[0m\n",
      "│       │   │   │       ├── \u001b[34;42massets\u001b[0m\n",
      "│       │   │   │       ├── \u001b[01;32mfingerprint.pb\u001b[0m\n",
      "│       │   │   │       ├── \u001b[01;32msaved_model.pb\u001b[0m\n",
      "│       │   │   │       └── \u001b[34;42mvariables\u001b[0m\n",
      "│       │   │   │           ├── \u001b[01;32mvariables.data-00000-of-00001\u001b[0m\n",
      "│       │   │   │           └── \u001b[01;32mvariables.index\u001b[0m\n",
      "│       │   │   └── \u001b[34;42m5\u001b[0m\n",
      "│       │   │       ├── \u001b[34;42mmetadata\u001b[0m\n",
      "│       │   │       │   └── \u001b[01;32mschema.pbtxt\u001b[0m\n",
      "│       │   │       ├── \u001b[34;42mtransformed_metadata\u001b[0m\n",
      "│       │   │       │   └── \u001b[01;32mschema.pbtxt\u001b[0m\n",
      "│       │   │       └── \u001b[34;42mtransform_fn\u001b[0m\n",
      "│       │   │           ├── \u001b[34;42massets\u001b[0m\n",
      "│       │   │           ├── \u001b[01;32mfingerprint.pb\u001b[0m\n",
      "│       │   │           ├── \u001b[01;32msaved_model.pb\u001b[0m\n",
      "│       │   │           └── \u001b[34;42mvariables\u001b[0m\n",
      "│       │   │               ├── \u001b[01;32mvariables.data-00000-of-00001\u001b[0m\n",
      "│       │   │               └── \u001b[01;32mvariables.index\u001b[0m\n",
      "│       │   └── \u001b[34;42mupdated_analyzer_cache\u001b[0m\n",
      "│       │       ├── \u001b[34;42m13\u001b[0m\n",
      "│       │       ├── \u001b[34;42m27\u001b[0m\n",
      "│       │       ├── \u001b[34;42m33\u001b[0m\n",
      "│       │       └── \u001b[34;42m5\u001b[0m\n",
      "│       ├── \u001b[34;42mTuner\u001b[0m\n",
      "│       │   ├── \u001b[34;42mbest_hyperparameters\u001b[0m\n",
      "│       │   │   ├── \u001b[34;42m21\u001b[0m\n",
      "│       │   │   │   └── \u001b[01;32mbest_hyperparameters.txt\u001b[0m\n",
      "│       │   │   ├── \u001b[34;42m34\u001b[0m\n",
      "│       │   │   │   └── \u001b[01;32mbest_hyperparameters.txt\u001b[0m\n",
      "│       │   │   └── \u001b[34;42m7\u001b[0m\n",
      "│       │   └── \u001b[34;42mtuner_results\u001b[0m\n",
      "│       │       ├── \u001b[34;42m21\u001b[0m\n",
      "│       │       │   └── \u001b[01;32mtuner_results.json\u001b[0m\n",
      "│       │       ├── \u001b[34;42m34\u001b[0m\n",
      "│       │       │   └── \u001b[01;32mtuner_results.json\u001b[0m\n",
      "│       │       └── \u001b[34;42m7\u001b[0m\n",
      "│       └── \u001b[34;42m_wheels\u001b[0m\n",
      "│           ├── \u001b[01;32mtfx_user_code_Trainer-0.0+32fdad56e4b765916be5c6b7b26f874c2c97cc69997a7f9ec709e82015a50087-py3-none-any.whl\u001b[0m\n",
      "│           ├── \u001b[01;32mtfx_user_code_Trainer-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f-py3-none-any.whl\u001b[0m\n",
      "│           ├── \u001b[01;32mtfx_user_code_Trainer-0.0+92dcb0d6a9fcfaf166fa9f1cb9daa7992f56279c35142e62d685160b54040c41-py3-none-any.whl\u001b[0m\n",
      "│           ├── \u001b[01;32mtfx_user_code_Transform-0.0+32fdad56e4b765916be5c6b7b26f874c2c97cc69997a7f9ec709e82015a50087-py3-none-any.whl\u001b[0m\n",
      "│           ├── \u001b[01;32mtfx_user_code_Transform-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f-py3-none-any.whl\u001b[0m\n",
      "│           ├── \u001b[01;32mtfx_user_code_Transform-0.0+92dcb0d6a9fcfaf166fa9f1cb9daa7992f56279c35142e62d685160b54040c41-py3-none-any.whl\u001b[0m\n",
      "│           ├── \u001b[01;32mtfx_user_code_Tuner-0.0+32fdad56e4b765916be5c6b7b26f874c2c97cc69997a7f9ec709e82015a50087-py3-none-any.whl\u001b[0m\n",
      "│           ├── \u001b[01;32mtfx_user_code_Tuner-0.0+8d9edda989efc3b5c9d7225c68a8044f68ad1fe158b02cb4e4dd4519e955e20f-py3-none-any.whl\u001b[0m\n",
      "│           └── \u001b[01;32mtfx_user_code_Tuner-0.0+92dcb0d6a9fcfaf166fa9f1cb9daa7992f56279c35142e62d685160b54040c41-py3-none-any.whl\u001b[0m\n",
      "├── \u001b[01;32mPylint_check.ipynb\u001b[0m\n",
      "└── \u001b[01;32mrequirements.txt\u001b[0m\n",
      "\n",
      "121 directories, 96 files\n"
     ]
    }
   ],
   "source": [
    "!tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PENJELASAN DARI TAHAP-TAHAP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. FILE local_pipeline.py**\n",
    "\n",
    "File `local_pipeline.py` adalah sebuah modul Python yang bertanggung jawab untuk menginisialisasi dan menjalankan sebuah pipeline machine learning menggunakan TensorFlow Extended (TFX) dalam lingkungan lokal. Modul ini berfungsi sebagai titik masuk utama atau skrip pengatur yang mengatur alur kerja keseluruhan dari pipeline ML, mulai dari pra-pemrosesan data hingga pelatihan model dan penyimpanan hasilnya.\n",
    "\n",
    "### Tugas Utama:\n",
    "1. **Inisialisasi Komponen Pipeline**: Memuat dan mengonfigurasi komponen-komponen TFX seperti `CsvExampleGen`, `StatisticsGen`, `SchemaGen`, `ExampleValidator`, `Transform`, `Tuner`, `Trainer`, `Resolver`, `Evaluator`, dan `Pusher`.\n",
    "2. **Penentuan Konfigurasi Pipeline**: Menetapkan parameter-parameter seperti lokasi data masukan, lokasi output, dan konfigurasi lain yang diperlukan untuk menjalankan pipeline dengan benar.\n",
    "3. **Pembentukan Pipeline**: Menggabungkan semua komponen dan konfigurasi ke dalam sebuah objek `pipeline.Pipeline` yang mewakili alur eksekusi dari setiap komponen dalam pipeline.\n",
    "4. **Eksekusi Pipeline**: Menjalankan pipeline menggunakan `BeamDagRunner`, yang akan mengeksekusi setiap komponen secara berurutan sesuai dengan alur yang ditentukan.\n",
    "\n",
    "Dengan menggunakan file `local_pipeline.py`, pengguna dapat dengan mudah mengatur dan menjalankan pipeline ML mereka dalam lingkungan lokal dengan hanya melakukan pengaturan konfigurasi yang sesuai dan menjalankan skrip tersebut. Ini memberikan fleksibilitas dan kemudahan dalam pengembangan, pengujian, dan penyebaran model ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile \"local_pipeline.py\"\n",
    "\n",
    "\"\"\"\n",
    "Author: Tomb\n",
    "Date: 3/30/2024\n",
    "This is the local_pipeline.py module.\n",
    "Usage:\n",
    "    this is the main of starting pipeline for running\n",
    "    pipelne. This module will create pipeline environtment\n",
    "    and initialize it.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from typing import Text\n",
    "from absl import logging\n",
    "from tfx.orchestration import metadata, pipeline\n",
    "from tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\n",
    "\n",
    "PIPELINE_NAME = \"sitomb-pipeline\"\n",
    "\n",
    "# pipeline inputs\n",
    "DATA_ROOT = \"dataset\"\n",
    "TRANSFORM_MODULE_FILE = \"modules/transform.py\"\n",
    "TRAINER_MODULE_FILE = \"modules/trainer.py\"\n",
    "TUNER_MODULE_FILE = \"modules/tuner.py\"\n",
    "\n",
    "# pipeline outputs\n",
    "OUTPUT_BASE = \"output\"\n",
    "serving_model_dir = os.path.join(OUTPUT_BASE, 'serving_model')\n",
    "pipeline_root = os.path.join(OUTPUT_BASE, PIPELINE_NAME)\n",
    "metadata_path = os.path.join(pipeline_root, \"metadata.sqlite\")\n",
    "\n",
    "\n",
    "def init_local_pipeline(component_arg, pipeline_root_arg: Text\n",
    "                        ) -> pipeline.Pipeline:\n",
    "    \"\"\"\n",
    "    init_local_pipeline that start everything\n",
    "\n",
    "    Init local pipeline for initialize pipeline\n",
    "    and defined environtment above (Output_Base dkk)\n",
    "\n",
    "    Returns:\n",
    "    TFX pipeline sent to apache beam\n",
    "    \"\"\"\n",
    "\n",
    "    logging.info(f\"Pipeline root set to: {pipeline_root}\")\n",
    "    beam_args = [\n",
    "        \"--direct_running_mode=multi_processing\"\n",
    "        # 0 auto-detect based on on the number of CPUs available\n",
    "        # during execution time.\n",
    "        \"----direct_num_workers=0\"\n",
    "    ]\n",
    "\n",
    "    return pipeline.Pipeline(\n",
    "        pipeline_name=PIPELINE_NAME,\n",
    "        pipeline_root=pipeline_root_arg,\n",
    "        components=component_arg,\n",
    "        enable_cache=True,\n",
    "        metadata_connection_config=metadata.sqlite_metadata_connection_config(\n",
    "            metadata_path\n",
    "        ),\n",
    "        eam_pipeline_args=beam_args\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logging.set_verbosity(logging.INFO)\n",
    "\n",
    "    from modules.components import init_components\n",
    "\n",
    "    components = init_components({\n",
    "        \"data_dir\": DATA_ROOT,\n",
    "        \"training_module\": TRAINER_MODULE_FILE,\n",
    "        \"transform_module\": TRANSFORM_MODULE_FILE,\n",
    "        \"tuner_module\": TUNER_MODULE_FILE,\n",
    "        \"training_steps\": 5000,\n",
    "        \"eval_steps\": 1000,\n",
    "        \"serving_model_dir\": serving_model_dir\n",
    "    })\n",
    "\n",
    "    pipeline = init_local_pipeline(components, pipeline_root)\n",
    "    BeamDagRunner().run(pipeline=pipeline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. MODUL components.py**\n",
    "\n",
    "## components.py\n",
    "\n",
    "Modul `components.py` adalah bagian dari sistem pipeline Machine Learning yang bertanggung jawab untuk menginisialisasi komponen-komponen yang diperlukan dalam alur kerja pipeline. Modul ini mendefinisikan fungsi `init_components` yang menghasilkan dan mengkonfigurasi komponen-komponen TFX seperti `CsvExampleGen`, `StatisticsGen`, `SchemaGen`, `ExampleValidator`, `Transform`, `Tuner`, `Trainer`, `Resolver`, `Evaluator`, dan `Pusher`.\n",
    "\n",
    "### Fungsi Utama:\n",
    "- **init_components(arguments)**: Fungsi ini menerima sebuah argumen `arguments` berupa dictionary yang berisi konfigurasi seperti lokasi data, modul transformasi, modul pelatihan, jumlah langkah pelatihan, jumlah langkah evaluasi, dan direktori model yang akan disajikan. Fungsi ini mengembalikan tuple yang berisi semua komponen yang telah diinisialisasi dan dikonfigurasi sesuai dengan argumen yang diberikan.\n",
    "\n",
    "Dengan menggunakan modul `components.py`, pengguna dapat dengan mudah mengatur dan mengkonfigurasi komponen-komponen dalam sistem pipeline mereka dengan hanya memberikan argumen yang sesuai ke dalam fungsi `init_components`. Ini memungkinkan pengguna untuk mempercepat pengembangan dan penyesuaian alur kerja pipeline mereka sesuai kebutuhan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir \"modules\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile \"modules/components.py\"\n",
    "\n",
    "\"\"\"\n",
    "Author: Tomb\n",
    "Date: 3/30/2024\n",
    "This is the components.py module.\n",
    "Usage:\n",
    "    this is the main of starting pipeline\n",
    "    components for running\n",
    "    pipeline.\n",
    "\"\"\"\n",
    "import os\n",
    "import tfx\n",
    "import tensorflow_model_analysis as tfma\n",
    "from tfx.components import (CsvExampleGen, StatisticsGen,\n",
    "                    SchemaGen, ExampleValidator, Transform,\n",
    "                    Tuner, Trainer, Evaluator, Pusher)\n",
    "from tfx.types import Channel\n",
    "from tfx.dsl.components.common.resolver import Resolver\n",
    "from tfx.types.standard_artifacts import Model, ModelBlessing\n",
    "from tfx.dsl.input_resolution.strategies.latest_blessed_model_strategy import (\n",
    "    LatestBlessedModelStrategy\n",
    ")\n",
    "\n",
    "LABEL_KEY = \"clickbait\"\n",
    "FEATURE_KEY = \"headline\"\n",
    "\n",
    "def init_components(arguments):\n",
    "    \"\"\"Initiate tfx pipeline components\n",
    "\n",
    "    arguments is dictionary include:\n",
    "        data_dir (str): a path to the data\n",
    "        transform_module (str): a path to the transform_module\n",
    "        training_module (str): a path to the transform_module\n",
    "        training_steps (int): number of training steps\n",
    "        eval_steps (int): number of eval steps\n",
    "        serving_model_dir (str): a path to the serving model directory\n",
    "\n",
    "    Returns:\n",
    "        TFX components\n",
    "    \"\"\"\n",
    "\n",
    "    example_gen = CsvExampleGen(\n",
    "        input_base=arguments[\"data_dir\"]\n",
    "    )\n",
    "\n",
    "    statistics_gen = StatisticsGen(\n",
    "        examples=example_gen.outputs[\"examples\"]\n",
    "    )\n",
    "\n",
    "    schema_gen = SchemaGen(\n",
    "        statistics=statistics_gen.outputs[\"statistics\"]\n",
    "    )\n",
    "\n",
    "    example_validator = ExampleValidator(\n",
    "        statistics=statistics_gen.outputs['statistics'],\n",
    "        schema=schema_gen.outputs['schema']\n",
    "    )\n",
    "\n",
    "    transform = Transform(\n",
    "        examples=example_gen.outputs['examples'],\n",
    "        schema=schema_gen.outputs['schema'],\n",
    "        module_file=os.path.abspath(arguments[\"transform_module\"])\n",
    "    )\n",
    "\n",
    "    tuner = Tuner(\n",
    "        module_file=os.path.abspath(arguments[\"tuner_module\"]),\n",
    "        examples=transform.outputs[\"transformed_examples\"],\n",
    "        transform_graph=transform.outputs[\"transform_graph\"],\n",
    "        schema=schema_gen.outputs[\"schema\"],\n",
    "        train_args=tfx.v1.proto.TrainArgs(\n",
    "            splits=[\"train\"],\n",
    "            num_steps=arguments[\"training_steps\"],\n",
    "        ),\n",
    "        eval_args=tfx.v1.proto.EvalArgs(\n",
    "            splits=[\"eval\"],\n",
    "            num_steps=arguments[\"eval_steps\"],\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        module_file=os.path.abspath(arguments[\"training_module\"]),\n",
    "        examples=transform.outputs['transformed_examples'],\n",
    "        transform_graph=transform.outputs['transform_graph'],\n",
    "        schema=schema_gen.outputs['schema'],\n",
    "        hyperparameters=tuner.outputs[\"best_hyperparameters\"],\n",
    "        train_args=tfx.v1.proto.TrainArgs(\n",
    "            splits=['train'],\n",
    "            num_steps=arguments[\"training_steps\"]),\n",
    "        eval_args=tfx.v1.proto.EvalArgs(\n",
    "            splits=['eval'],\n",
    "            num_steps=arguments[\"eval_steps\"])\n",
    "    )\n",
    "\n",
    "    model_resolver = Resolver(\n",
    "        strategy_class=LatestBlessedModelStrategy,\n",
    "        model=Channel(type=Model),\n",
    "        model_blessing=Channel(type=ModelBlessing)\n",
    "    ).with_id('Latest_blessed_model_resolver')\n",
    "\n",
    "    slicing_specs = [\n",
    "        tfma.SlicingSpec(),\n",
    "        tfma.SlicingSpec(feature_keys=FEATURE_KEY)\n",
    "    ]\n",
    "\n",
    "    metrics_specs = [\n",
    "        tfma.MetricsSpec(metrics=[\n",
    "                tfma.MetricConfig(class_name='AUC'),\n",
    "                tfma.MetricConfig(class_name=\"Precision\"),\n",
    "                tfma.MetricConfig(class_name=\"Recall\"),\n",
    "                tfma.MetricConfig(class_name=\"ExampleCount\"),\n",
    "                tfma.MetricConfig(class_name='BinaryAccuracy',\n",
    "                    threshold=tfma.MetricThreshold(\n",
    "                        value_threshold=tfma.GenericValueThreshold(\n",
    "                            lower_bound={'value': 0.5}),\n",
    "                        change_threshold=tfma.GenericChangeThreshold(\n",
    "                            direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n",
    "                            absolute={'value': 0.0001})\n",
    "                        )\n",
    "                )\n",
    "            ])\n",
    "    ]\n",
    "\n",
    "    eval_config = tfma.EvalConfig(\n",
    "        model_specs=[tfma.ModelSpec(label_key=LABEL_KEY)],\n",
    "        slicing_specs=slicing_specs,\n",
    "        metrics_specs=metrics_specs\n",
    "    )\n",
    "\n",
    "    evaluator = Evaluator(\n",
    "        examples=example_gen.outputs['examples'],\n",
    "        model=trainer.outputs['model'],\n",
    "        baseline_model=model_resolver.outputs['model'],\n",
    "        eval_config=eval_config)\n",
    "\n",
    "    pusher = Pusher(\n",
    "        model=trainer.outputs[\"model\"],\n",
    "        model_blessing=evaluator.outputs[\"blessing\"],\n",
    "        push_destination=tfx.v1.proto.PushDestination(\n",
    "            filesystem=tfx.v1.proto.PushDestination.Filesystem(\n",
    "                base_directory=arguments[\"serving_model_dir\"]\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    components = (\n",
    "        example_gen,\n",
    "        statistics_gen,\n",
    "        schema_gen,\n",
    "        example_validator,\n",
    "        transform,\n",
    "        tuner,\n",
    "        trainer,\n",
    "        model_resolver,\n",
    "        evaluator,\n",
    "        pusher\n",
    "    )\n",
    "    return components\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. MODUL transform.py**\n",
    "\n",
    "Modul `transform.py` merupakan bagian dari pipeline Machine Learning yang bertanggung jawab untuk melakukan pra-pemrosesan atau transformasi data sebelum dilakukan pelatihan model. Modul ini menyediakan fungsi-fungsi untuk melakukan transformasi fitur-fitur input menjadi format yang sesuai untuk diproses oleh model.\n",
    "\n",
    "### Fungsi Utama:\n",
    "- **transformed_name(key)**: Fungsi ini mengembalikan nama fitur yang telah ditransformasi berdasarkan kunci fitur yang diberikan. Misalnya, fitur kunci \"headline\" dapat diubah menjadi \"headline_xf\" setelah transformasi.\n",
    "- **preprocessing_fn(inputs)**: Fungsi ini melakukan pra-pemrosesan pada fitur-fitur input yang diberikan. Fitur-fitur input diubah sesuai dengan kebutuhan, seperti mengonversi teks menjadi huruf kecil atau mengubah label menjadi tipe data yang sesuai.\n",
    "\n",
    "Dengan menggunakan modul `transform.py`, pengguna dapat dengan mudah melakukan pra-pemrosesan data sebelum dilakukan pelatihan model. Ini memungkinkan pengguna untuk mempersiapkan data dengan cara yang sesuai dengan kebutuhan model mereka sebelum proses pelatihan dimulai.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Tomb\n",
    "Date: 3/27/2024\n",
    "This is the transform.py module.\n",
    "Usage:\n",
    "- For Transorm Feature into integer. Headline string > integer\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "LABEL_KEY = \"clickbait\"\n",
    "FEATURE_KEY = \"headline\"\n",
    "\n",
    "\n",
    "def transformed_name(key):\n",
    "    \"\"\"Transform feature key\n",
    "\n",
    "    Args:\n",
    "        key (str): the key to be transformed\n",
    "\n",
    "    Returns:\n",
    "        str: transformed key\n",
    "    \"\"\"\n",
    "\n",
    "    return f\"{key}_xf\"\n",
    "\n",
    "\n",
    "def preprocessing_fn(inputs):\n",
    "    \"\"\"Preprocess input features into transformed features\n",
    "\n",
    "    Args:\n",
    "        inputs (dict): map from feature keys to raw features\n",
    "\n",
    "    Returns:\n",
    "        dict: map from features keys to transformed features\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    outputs = {}\n",
    "\n",
    "    outputs[transformed_name(FEATURE_KEY)] = tf.strings.lower(\n",
    "        inputs[FEATURE_KEY])\n",
    "\n",
    "    outputs[transformed_name(LABEL_KEY)] = tf.cast(inputs[LABEL_KEY], tf.int64)\n",
    "\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. MODUL Tuner.py**\n",
    "Modul `tuner.py` adalah bagian dari pipeline Machine Learning yang menyediakan fungsionalitas untuk melakukan penyetelan otomatis terhadap hiperparameter model menggunakan KerasTuner. Modul ini bertanggung jawab untuk mencari hiperparameter terbaik untuk model ML melalui eksperimen berbagai kombinasi hiperparameter.\n",
    "\n",
    "### Fungsi Utama:\n",
    "- **tuner_fn(fn_args)**: Fungsi ini merupakan inti dari modul tuner yang digunakan dalam komponen `Tuner` pada pipeline ML. Fungsi ini menerima argumen `fn_args` yang berisi informasi tentang lokasi data, grafik transformasi, dan hiperparameter yang akan disetel. Selanjutnya, fungsi ini mengembalikan objek tuner beserta argumen-argumen untuk melatih model dengan hiperparameter terbaik yang ditemukan.\n",
    "\n",
    "### Fitur Utama:\n",
    "- **build_model(hp, vectorizer_layer)**: Fungsi ini digunakan untuk membangun model ML dengan arsitektur yang ditentukan. Fungsi ini menerima objek Hyperparameters (`hp`) dari KerasTuner dan layer vektorisasi teks sebagai argumen. Selanjutnya, fungsi ini mengembalikan model Keras yang telah dibangun dengan arsitektur yang sesuai dengan hiperparameter yang ditemukan.\n",
    "- **input_data(file_pattern, transform_output, num_epochs, batch_size)**: Fungsi ini digunakan untuk mempersiapkan dataset untuk pelatihan dan evaluasi model. Fungsi ini menerima pola file, output transformasi, jumlah epoch, dan ukuran batch sebagai argumen, dan mengembalikan dataset yang siap untuk digunakan.\n",
    "\n",
    "Modul `tuner.py` memungkinkan pengguna untuk secara otomatis menemukan kombinasi hiperparameter terbaik untuk model ML mereka dengan menggunakan teknik penyetelan otomatis. Ini membantu meningkatkan kinerja dan generalisasi model tanpa perlu melakukan penyetelan secara manual.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Tomb\n",
    "Date: 3/30/2024\n",
    "This module provides auto hyperparameter tuning for TensorFlow\n",
    "models in TFX pipelines using KerasTuner.\n",
    "Usage:\n",
    "    Use within a TFX pipeline component\n",
    "    for optimizing model\n",
    "    parameters based on specified\n",
    "    metrics and trials.\n",
    "\"\"\"\n",
    "from typing import NamedTuple, Dict, Text, Any\n",
    "from tfx.components.trainer.fn_args_utils import FnArgs\n",
    "from kerastuner.engine import base_tuner\n",
    "from kerastuner import Hyperband, Objective\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "from transform import (LABEL_KEY, FEATURE_KEY, transformed_name)\n",
    "\n",
    "# Constants\n",
    "NUM_EPOCHS = 1\n",
    "MAX_TOKEN = 5000\n",
    "SEQUENCE_LENGTH = 100\n",
    "\n",
    "# NamedTuple for Tuner Function Result\n",
    "TunerResult = NamedTuple(\"TunerResult\", [\n",
    "    (\"tuner\", base_tuner.BaseTuner),\n",
    "    (\"fit_kwargs\", Dict[Text, Any]),\n",
    "])\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_binary_accuracy\",\n",
    "    mode=\"max\",\n",
    "    verbose=1,\n",
    "    patience=5,\n",
    ")\n",
    "\n",
    "\n",
    "def gzip_reader(filenames):\n",
    "    \"\"\"\n",
    "    Creates a TFRecordDataset to read TFRecord files with GZIP compression.\n",
    "        This function takes a list of filenames pointing to\n",
    "        TFRecord files compressed using GZIP and returns a `tf.data.TFRecordDataset`\n",
    "        object configured to read them.\n",
    "\n",
    "    Parameters:\n",
    "    - filenames (list of str or str): A list of filenames (paths) of the\n",
    "        TFRecord files to read. If a single filename is provided,\n",
    "        it is wrapped in a list automatically.\n",
    "    \"\"\"\n",
    "    return tf.data.TFRecordDataset(filenames, compression_type=\"GZIP\")\n",
    "\n",
    "\n",
    "def input_data(file_pattern, transform_output, num_epochs, batch_size=64):\n",
    "    \"\"\"\n",
    "    Prepares a batched dataset from TFRecord files using the provided transformation schema.\n",
    "     Parameters:\n",
    "    - file_pattern (str): A string pattern that matches the TFRecord files to read.\n",
    "    - transform_output: object containing the transformation schema \n",
    "    - num_epochs (int): The number of times the dataset should be repeated. \n",
    "    - batch_size (int): The number of records to combine in a single batch.\n",
    "    \"\"\"\n",
    "    transform_feature_spec = (\n",
    "        transform_output.transformed_feature_spec().copy()\n",
    "    )\n",
    "\n",
    "    dataset = tf.data.experimental.make_batched_features_dataset(\n",
    "        file_pattern=file_pattern,\n",
    "        batch_size=batch_size,\n",
    "        features=transform_feature_spec,\n",
    "        reader=gzip_reader,\n",
    "        num_epochs=num_epochs,\n",
    "        label_key=transformed_name(LABEL_KEY),\n",
    "    )\n",
    "\n",
    "    return dataset\n",
    "\n",
    "# Model Building Function\n",
    "\n",
    "\n",
    "def build_model(hp, vectorizer_layer):\n",
    "    \"\"\"\n",
    "    Create model based\n",
    "    \"\"\"\n",
    "    num_hidden_layers = hp.Choice(\"num_hidden_layers\", values=[1, 2, 3])\n",
    "    embed_dims = hp.Int(\"embed_dims\", min_value=16, max_value=256, step=32)\n",
    "    lstm_units = hp.Int(\"lstm_units\", min_value=32, max_value=256, step=32)\n",
    "    dense_units = hp.Int(\"dense_units\", min_value=64, max_value=512, step=64)\n",
    "    dropout_rate = hp.Float(\n",
    "        \"dropout_rate\",\n",
    "        min_value=0.2,\n",
    "        max_value=0.5,\n",
    "        step=0.1)\n",
    "    learning_rate = hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4, 1e-5])\n",
    "\n",
    "    inputs = tf.keras.Input(\n",
    "        shape=(\n",
    "            1,\n",
    "        ),\n",
    "        name=transformed_name(FEATURE_KEY),\n",
    "        dtype=tf.string)\n",
    "\n",
    "    x = vectorizer_layer(inputs)\n",
    "    x = layers.Embedding(input_dim=5000, output_dim=embed_dims)(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(lstm_units))(x)\n",
    "\n",
    "    for _ in range(num_hidden_layers):\n",
    "        x = layers.Dense(dense_units, activation=tf.nn.relu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    outputs = layers.Dense(1, activation=tf.nn.sigmoid)(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "        metrics=[\"binary_accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Tuner Function\n",
    "\n",
    "\n",
    "def tuner_fn(fn_args: FnArgs):\n",
    "    \"\"\"\n",
    "    main tuner function\n",
    "    \"\"\"\n",
    "    transform_output = tft.TFTransformOutput(fn_args.transform_graph_path)\n",
    "\n",
    "    train_data = input_data(\n",
    "        fn_args.train_files[0], transform_output, NUM_EPOCHS\n",
    "    )\n",
    "    eval_data = input_data(\n",
    "        fn_args.eval_files[0], transform_output, NUM_EPOCHS\n",
    "    )\n",
    "\n",
    "    vectorizer_dataset = train_data.map(\n",
    "        lambda f, l: f[transformed_name(FEATURE_KEY)]\n",
    "    )\n",
    "\n",
    "    vectorizer_layer = layers.TextVectorization(\n",
    "        max_tokens=MAX_TOKEN,\n",
    "        output_mode=\"int\",\n",
    "        output_sequence_length=SEQUENCE_LENGTH,\n",
    "    )\n",
    "    print(\"DEBUG: Start_vectorizer_adapt\")\n",
    "    vectorizer_layer.adapt(vectorizer_dataset)\n",
    "    print(\"DEBUG: Finish Vectorizer Adapt\")\n",
    "\n",
    "    tuner = Hyperband(\n",
    "        hypermodel=lambda hp: build_model(hp, vectorizer_layer),\n",
    "        objective=Objective('val_binary_accuracy', direction='max'),\n",
    "        max_epochs=NUM_EPOCHS,\n",
    "        factor=3,\n",
    "        directory=fn_args.working_dir,\n",
    "        project_name=\"clickbait_detection_hyperband_kt\",\n",
    "    )\n",
    "\n",
    "    return TunerResult(\n",
    "        tuner=tuner,\n",
    "        fit_kwargs={\n",
    "            \"callbacks\": [early_stopping_cb],\n",
    "            \"x\": train_data,\n",
    "            \"validation_data\": eval_data,\n",
    "            \"steps_per_epoch\": 50,\n",
    "            \"validation_steps\": 25,\n",
    "        },\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. MODUL trainer.py**\n",
    "Modul `trainer.py` merupakan bagian dari pipeline Machine Learning yang bertanggung jawab untuk melatih model ML dengan menggunakan data yang telah diproses sebelumnya. Modul ini menyediakan fungsi-fungsi untuk membangun, melatih, dan mengevaluasi model ML menggunakan TensorFlow.\n",
    "\n",
    "### Fungsi Utama:\n",
    "- **model_builder(hyperparameters, show_summary=True)**: Fungsi ini digunakan untuk membangun arsitektur model ML berdasarkan hiperparameter yang diberikan. Fungsi ini menerima hiperparameter, seperti jumlah lapisan tersembunyi, ukuran batch, dan tingkat dropout, serta menampilkan ringkasan model jika `show_summary` diatur ke `True`.\n",
    "- **run_fn(fn_args)**: Fungsi ini merupakan inti dari modul trainer yang digunakan dalam komponen `Trainer` pada pipeline ML. Fungsi ini menerima argumen `fn_args` yang berisi informasi tentang lokasi data latih, data evaluasi, grafik transformasi, dan hiperparameter yang akan digunakan. Selanjutnya, fungsi ini membangun, melatih, dan mengevaluasi model ML dengan menggunakan data yang diberikan.\n",
    "\n",
    "### Fitur Utama:\n",
    "- **input_fn(file_pattern, tf_transform_output, num_epochs, batch_size)**: Fungsi ini digunakan untuk mempersiapkan dataset untuk pelatihan dan evaluasi model. Fungsi ini menerima pola file, output transformasi, jumlah epoch, dan ukuran batch sebagai argumen, dan mengembalikan dataset yang siap digunakan.\n",
    "- **_get_serve_tf_examples_fn(model, tf_transform_output)**: Fungsi ini digunakan untuk membuat fungsi TensorFlow untuk melayani contoh-contoh TensorFlow yang di-serialisasi secara mentah. Fungsi ini membantu dalam menyajikan model yang telah dilatih secara online menggunakan TensorFlow Serving.\n",
    "\n",
    "Modul `trainer.py` memungkinkan pengguna untuk membangun, melatih, dan mengevaluasi model ML dengan mudah menggunakan TensorFlow. Ini memfasilitasi pengguna dalam menjalankan pelatihan model secara efisien dan melakukan evaluasi kinerja model untuk pengembangan yang lebih lanjut.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Tomb\n",
    "Date: 3/30/2024\n",
    "This is the trainer.py module.\n",
    "Usage:\n",
    "    this is the main of training pipeline\n",
    "    models when running pipeline.\n",
    "\"\"\"\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "from tensorflow.keras import layers\n",
    "from tfx.components.trainer.fn_args_utils import FnArgs\n",
    "from transform import (\n",
    "    LABEL_KEY,\n",
    "    FEATURE_KEY,\n",
    "    transformed_name,\n",
    ")\n",
    "\n",
    "VOCAB_SIZE = 10000\n",
    "EMBEDDING_DIM = 16\n",
    "SEQUENCE_LENGTH = 100\n",
    "\n",
    "\n",
    "def gzip_reader_fn(filenames):\n",
    "    \"\"\"Loads compressed data\"\"\"\n",
    "    return tf.data.TFRecordDataset(filenames, compression_type='GZIP')\n",
    "\n",
    "\n",
    "def input_fn(file_pattern,\n",
    "             tf_transform_output,\n",
    "             num_epochs,\n",
    "             batch_size=64) -> tf.data.Dataset:\n",
    "    \"\"\"Get post_tranform feature & create batches of data\"\"\"\n",
    "\n",
    "    transform_feature_spec = (\n",
    "        tf_transform_output.transformed_feature_spec().copy())\n",
    "\n",
    "    dataset = tf.data.experimental.make_batched_features_dataset(\n",
    "        file_pattern=file_pattern,\n",
    "        batch_size=batch_size,\n",
    "        features=transform_feature_spec,\n",
    "        reader=gzip_reader_fn,\n",
    "        num_epochs=num_epochs,\n",
    "        label_key=transformed_name(LABEL_KEY))\n",
    "    return dataset\n",
    "\n",
    "\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    standardize=\"lower_and_strip_punctuation\",\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=SEQUENCE_LENGTH)\n",
    "\n",
    "\n",
    "def model_builder(hyperparameters, show_summary=True):\n",
    "    \"\"\"\n",
    "    This function defines a Keras model and returns the model as a\n",
    "    Keras object.\n",
    "    \"\"\"\n",
    "    input_features = []\n",
    "\n",
    "    for key, dim in CATEGORICAL_FEATURES.items():\n",
    "        input_features.append(\n",
    "            tf.keras.Input(shape=(dim + 1,), name=transformed_name(key))\n",
    "        )\n",
    "\n",
    "    for feature in NUMERICAL_FEATURES:\n",
    "        input_features.append(\n",
    "            tf.keras.Input(shape=(1,), name=transformed_name(feature))\n",
    "        )\n",
    "\n",
    "    concatenate = tf.keras.layers.concatenate(input_features)\n",
    "    \n",
    "    deep = tf.keras.layers.Dense(\n",
    "        hyperparameters[\"dense_unit\"], activation=tf.nn.relu)(concatenate)\n",
    "\n",
    "    for _ in range(hyperparameters[\"num_hidden_layers\"]):\n",
    "        deep = tf.keras.layers.Dense(\n",
    "            hyperparameters[\"dense_unit\"], activation=tf.nn.relu)(deep)\n",
    "        deep = tf.keras.layers.Dropout(hyperparameters[\"dropout_rate\"])(deep)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(deep)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=input_features, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
    "    )\n",
    "\n",
    "    if show_summary:\n",
    "        model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def _get_serve_tf_examples_fn(model, tf_transform_output):\n",
    "    \"\"\"\n",
    "    Creates a TensorFlow serving function that processes raw serialized TF examples.\n",
    "    \"\"\"\n",
    "\n",
    "    model.tft_layer = tf_transform_output.transform_features_layer()\n",
    "\n",
    "    @tf.function\n",
    "    def serve_tf_examples_fn(serialized_tf_examples):\n",
    "\n",
    "        feature_spec = tf_transform_output.raw_feature_spec()\n",
    "\n",
    "        feature_spec.pop(LABEL_KEY)\n",
    "\n",
    "        parsed_features = tf.io.parse_example(\n",
    "            serialized_tf_examples, feature_spec)\n",
    "\n",
    "        transformed_features = model.tft_layer(parsed_features)\n",
    "\n",
    "        return model(transformed_features)\n",
    "\n",
    "    return serve_tf_examples_fn\n",
    "\n",
    "\n",
    "def run_fn(fn_args: FnArgs) -> None:\n",
    "    \"\"\"\n",
    "    Main function of trainer module\n",
    "    \"\"\"\n",
    "\n",
    "    log_dir = os.path.join(os.path.dirname(fn_args.serving_model_dir), 'logs')\n",
    "\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=log_dir, update_freq='batch'\n",
    "    )\n",
    "\n",
    "    es = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_binary_accuracy',\n",
    "        mode='max',\n",
    "        verbose=1,\n",
    "        patience=10)\n",
    "    mc = tf.keras.callbacks.ModelCheckpoint(\n",
    "        fn_args.serving_model_dir,\n",
    "        monitor='val_binary_accuracy',\n",
    "        mode='max',\n",
    "        verbose=1,\n",
    "        save_best_only=True)\n",
    "\n",
    "    hyperparameters = fn_args.hyperparameters[\"values\"]\n",
    "    tf_transform_output = tft.TFTransformOutput(fn_args.transform_graph_path)\n",
    "\n",
    "    train_set = input_fn(fn_args.train_files, tf_transform_output, 10)\n",
    "    val_set = input_fn(fn_args.eval_files, tf_transform_output, 10)\n",
    "    print(\"vectorize_layer_start\")\n",
    "    vectorize_layer.adapt(\n",
    "        [j[0].numpy()[0] for j in [\n",
    "            i[0][transformed_name(FEATURE_KEY)]\n",
    "            for i in list(train_set)]])\n",
    "\n",
    "    print(\"Build_model_start\")\n",
    "    model = model_builder(hyperparameters, show_summary=True)\n",
    "\n",
    "    model.fit(x=train_set,\n",
    "              validation_data=val_set,\n",
    "              callbacks=[tensorboard_callback, es, mc],\n",
    "              steps_per_epoch=1000,\n",
    "              validation_steps=1000,\n",
    "              epochs=10)\n",
    "    signatures = {\n",
    "        'serving_default': _get_serve_tf_examples_fn(\n",
    "            model,\n",
    "            tf_transform_output).get_concrete_function(\n",
    "            tf.TensorSpec(\n",
    "                shape=[None],\n",
    "                dtype=tf.string,\n",
    "                name='examples'))}\n",
    "    model.save(\n",
    "        fn_args.serving_model_dir,\n",
    "        save_format='tf',\n",
    "        signatures=signatures)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
